{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Load Libraries and Check Version of TensorFlow Library"
      ],
      "metadata": {
        "id": "zPjvgmIkX07E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dEgRpy3952M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "74c8fcdd-982d-406e-82fd-fc71536f4458"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from keras.datasets import mnist\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting Printing Precision"
      ],
      "metadata": {
        "id": "VuI_-TVcYAp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BpVeIWIOks"
      },
      "source": [
        "### Load MNIST Data and Train Test Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5kaKFKSIQgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e35d17-66db-4a42-b08d-24c203f3a719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "MNIST set\n",
            "---------------------\n",
            "Number of training samples = 60000\n",
            "Number of features = 784\n",
            "Number of output labels = 10\n",
            "Shape of the X_train Matrix is: (784, 60000)\n"
          ]
        }
      ],
      "source": [
        "## Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.transpose(1, 2, 0)\n",
        "X_test = X_test.transpose(1, 2, 0)\n",
        "X_train = X_train.reshape(X_train.shape[0]*X_train.shape[1], X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0]*X_test.shape[1], X_test.shape[2])\n",
        "\n",
        "num_labels = len(np.unique(y_train))\n",
        "num_features = X_train.shape[0]\n",
        "num_samples = X_train.shape[1]\n",
        "\n",
        "# One-hot encode class labels\n",
        "Y_train = tf.keras.utils.to_categorical(y_train).T\n",
        "Y_test = tf.keras.utils.to_categorical(y_test).T\n",
        "\n",
        "\n",
        "# Normalize the samples (images)\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)\n",
        "\n",
        "print('MNIST set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))\n",
        "print('Number of output labels = %d'%(num_labels))\n",
        "print('Shape of the X_train Matrix is:', X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrXipxwrJ0_8"
      },
      "source": [
        "### A generic layer class with forward and backward methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4pKUhCyMrWm"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "  def __init__(self):\n",
        "    self.input = None\n",
        "    self.output = None\n",
        "\n",
        "  def forward(self, input):\n",
        "    pass\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the loss function and its gradient"
      ],
      "metadata": {
        "id": "XhobXZdAaKX0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdXSGW2s7zKd"
      },
      "outputs": [],
      "source": [
        "def cce(Y, Yhat):\n",
        "  return(np.mean(np.sum(-Y*np.log(Yhat), axis = 0)))\n",
        "  #TensorFlow in-built function for categorical crossentropy loss\n",
        "  #cce = tf.keras.losses.CategoricalCrossentropy()\n",
        "  #return(cce(Y, Yhat).numpy())\n",
        "\n",
        "def cce_gradient(Y, Yhat):\n",
        "  return(-Y/Yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define The Activation Layer and Its Forward and Backward Method"
      ],
      "metadata": {
        "id": "PeHsHv01aOP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_gradient):\n",
        "        self.activation = activation\n",
        "        self.activation_gradient = activation_gradient\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = self.activation(self.input)\n",
        "        return(self.output)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate = None):\n",
        "        return(self.activation_gradient(self.input) * output_gradient[:-1, :])"
      ],
      "metadata": {
        "id": "C21FcWIEwGCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specific activation layer classes:\n",
        "* Signoid Activation Function\n",
        "* Tanh Activation Function\n",
        "* ReLU Activation Function"
      ],
      "metadata": {
        "id": "JheGWSoKxYWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid(Activation):\n",
        "    def __init__(self):\n",
        "        def sigmoid(z):\n",
        "            return 1 / (1+np.exp(-z))\n",
        "\n",
        "        def sigmoid_gradient(z):\n",
        "            a = sigmoid(z)\n",
        "            return a * (1-a)\n",
        "\n",
        "        super().__init__(sigmoid, sigmoid_gradient)\n",
        "\n",
        "class Tanh(Activation):\n",
        "    def __init__(self):\n",
        "        def tanh(z):\n",
        "            return np.tanh(z)\n",
        "\n",
        "        def tanh_gradient(z):\n",
        "            a = np.tanh(z)\n",
        "            return (1-(a**2))\n",
        "\n",
        "        super().__init__(tanh, tanh_gradient)\n",
        "\n",
        "class ReLU(Activation):\n",
        "    def __init__(self):\n",
        "        def relu(z):\n",
        "            return z * (z > 0)\n",
        "\n",
        "        def relu_gradient(z):\n",
        "            return 1. * (z > 0)\n",
        "\n",
        "        super().__init__(relu, relu_gradient)"
      ],
      "metadata": {
        "id": "PQ5ybz_Yxbef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What the SoftMax Function is doing Interbally\n",
        "z = np.array([[10., 20., 30.], [-10., 50., 45.]]) # By giving a '.', convert them in flosting type values\n",
        "print(z)\n",
        "tf.nn.softmax(z, axis = 0).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDpmikNF1jmO",
        "outputId": "78759840-0435-4751-f0e5-b8016713fe40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 10.  20.  30.]\n",
            " [-10.  50.  45.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.00e+00, 9.36e-14, 3.06e-07],\n",
              "       [2.06e-09, 1.00e+00, 1.00e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax activation layer class and Its Forward and Backward Method\n"
      ],
      "metadata": {
        "id": "C-5Ch6ihanP0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x1Xn3AbJlNy"
      },
      "outputs": [],
      "source": [
        "class Softmax(Layer):\n",
        "  def forward(self, input):\n",
        "    self.output = tf.nn.softmax(input, axis = 0).numpy()\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate = None):\n",
        "    ## Following is the inefficient way of calculating the backward gradient\n",
        "    softmax_gradient = np.empty((self.output.shape[0], output_gradient.shape[1]), dtype = np.float64)\n",
        "    for b in range(softmax_gradient.shape[1]):\n",
        "      softmax_gradient[:, b] = np.dot((np.identity(self.output.shape[0])-np.atleast_2d(self.output[:, b])) * np.atleast_2d(self.output[:, b]).T, output_gradient[:, b])\n",
        "    return(softmax_gradient)\n",
        "    ## Following is the efficient way of calculating the backward gradient\n",
        "    #T = np.transpose(np.identity(self.output.shape[0]) - np.atleast_2d(self.output).T[:, np.newaxis, :], (2, 1, 0)) * np.atleast_2d(self.output)\n",
        "    #return(np.einsum('jik, ik -> jk', T, output_gradient))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense layer class and Its Forward and Backward Method\n"
      ],
      "metadata": {
        "id": "xxeuqOshauBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8ctXhZYCTmHK"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_size, output_size, reg_strength = 0.0):\n",
        "        self.weights = 0.01*np.random.randn(output_size, input_size + 1) # bias trick\n",
        "        self.weights[:, -1] = 0.01 # set all bias values to the same nonzero constant\n",
        "        self.reg_strength = reg_strength\n",
        "        self.reg_loss = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = np.vstack([input, np.ones((1, input.shape[1]))]) # bias trick\n",
        "        self.output= np.dot(self.weights, self.input)\n",
        "        # Calculate the regularization loss (L2 regularization)\n",
        "        self.reg_loss = self.reg_strength * np.sum(self.weights[:, :-1] * self.weights[:, :-1])\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        ## Following is the inefficient way of calculating the backward gradient\n",
        "        weights_gradient = np.zeros((self.output.shape[0], self.input.shape[0]), dtype = np.float64)\n",
        "        for b in range(output_gradient.shape[1]):\n",
        "          weights_gradient += np.dot(output_gradient[:, b].reshape(-1, 1), self.input[:, b].reshape(-1, 1).T)\n",
        "        weights_gradient = (1/output_gradient.shape[1])*weights_gradient\n",
        "\n",
        "        # Add the regularization loss gradient here\n",
        "        weights_gradient += 2*self.reg_strength * np.hstack([self.weights[:, :-1], np.zeros((self.weights.shape[0], 1))])\n",
        "\n",
        "        ## Following is the efficient way of calculating the weights gradient\n",
        "        #weights_gradient = (1/output_gradient.shape[1])*np.dot(np.atleast_2d(output_gradient), np.atleast_2d(self.input).T)\n",
        "\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "\n",
        "        # Update weights using gradient descent step\n",
        "        self.weights = self.weights + learning_rate * (-weights_gradient)\n",
        "\n",
        "        return(input_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W1howeOJegI"
      },
      "source": [
        "### Function to generate sample indices for batch processing according to batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MHyjEf22IRpc"
      },
      "outputs": [],
      "source": [
        "## Function to generate sample indices for batch processing according to batch size\n",
        "def generate_batch_indices(num_samples, batch_size):\n",
        "  # Reorder sample indices\n",
        "  reordered_sample_indices = np.random.choice(num_samples, num_samples, replace = False)\n",
        "  # Generate batch indices for batch processing\n",
        "  batch_indices = np.split(reordered_sample_indices, np.arange(batch_size, len(reordered_sample_indices), batch_size))\n",
        "  return(batch_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKFmCaFsJhkR"
      },
      "source": [
        "### Example generation of batch indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "k9QwikN0IYSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3494e991-002c-4126-97b1-77a7abfdf9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([20, 25,  8,  7, 16, 23, 30,  3]), array([19,  6,  4, 24, 27, 29, 13,  2]), array([12,  9, 21, 10, 31, 11,  0,  5]), array([15, 14, 17, 26, 28,  1, 22, 18])]\n"
          ]
        }
      ],
      "source": [
        "## Example generation of batch indices\n",
        "batch_size = 8\n",
        "batch_indices = generate_batch_indices(32, batch_size)\n",
        "print(batch_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI_Gms9fJqbs"
      },
      "source": [
        "### Train the 2-layer neural network (128 nodes in the hidden layer) using batch training with batch size = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train the 2-layer neural network (128 nodes in the hidden layer)\n",
        "## using batch training with batch size = 100\n",
        "learning_rate = 1e-3 # learning rate\n",
        "batch_size = 100 # batch size\n",
        "nepochs = 50 # number of epochs\n",
        "reg_strength = 0 # regularization strength\n",
        "\n",
        "# Create empty array to store training losses over each epoch\n",
        "loss_train_epoch = np.empty(nepochs, dtype = np.float64)\n",
        "\n",
        "# Create empty array to store test losses over each epoch\n",
        "loss_test_epoch = np.empty(nepochs, dtype = np.float64)\n",
        "\n",
        "# Define neural network architecture\n",
        "dlayer1 = Dense(num_features, 128, reg_strength) # define dense layer 1\n",
        "alayer1 = ReLU() # define activation layer 1\n",
        "dlayer2 = Dense(128, num_labels, reg_strength) # define dense layer 2\n",
        "softmax = Softmax() # define softmax activation layer\n",
        "\n",
        "# Steps: run over each batch, calculate average loss, average gradient of loss,\n",
        "# and update weights.\n",
        "\n",
        "epoch = 0\n",
        "while epoch < nepochs:\n",
        "  batch_indices = generate_batch_indices(num_samples, batch_size)\n",
        "  loss = 0\n",
        "  # Run over each batch\n",
        "  for b in range(len(batch_indices)):\n",
        "    # Forward prop starts here\n",
        "    dlayer1.forward(X_train[:, batch_indices[b]])\n",
        "    alayer1.forward(dlayer1.output)\n",
        "    dlayer2.forward(alayer1.output)\n",
        "    softmax.forward(dlayer2.output)\n",
        "\n",
        "    # Calculate training data loss\n",
        "    loss += cce(Y_train[:, batch_indices[b]], softmax.output)\n",
        "    loss += dlayer1.reg_loss + dlayer2.reg_loss\n",
        "\n",
        "    # Backward prop starts here\n",
        "    grad = cce_gradient(Y_train[:, batch_indices[b]], softmax.output)\n",
        "    grad = softmax.backward(grad)\n",
        "    grad = dlayer2.backward(grad, learning_rate)\n",
        "    grad = alayer1.backward(grad)\n",
        "    grad = dlayer1.backward(grad, learning_rate)\n",
        "\n",
        "  # Calculate the average training loss for the current epoch\n",
        "  loss_train_epoch[epoch] = loss / len(batch_indices)\n",
        "\n",
        "  # Forward propagation for the test data\n",
        "  dlayer1.forward(X_test)\n",
        "  alayer1.forward(dlayer1.output)\n",
        "  dlayer2.forward(alayer1.output)\n",
        "  softmax.forward(dlayer2.output)\n",
        "\n",
        "  # Calculate the test data loss for the current epoch\n",
        "  loss_test_epoch[epoch] = cce(Y_test, softmax.output) + dlayer1.reg_loss + dlayer2.reg_loss\n",
        "\n",
        "  print('Epoch %d: train loss = %f, test loss = %f'%(epoch+1, loss_train_epoch[epoch], loss_test_epoch[epoch]))\n",
        "  epoch = epoch + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b20wT5papntA",
        "outputId": "520bfa3a-2946-499e-b062-782536743d91"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss = 2.298704, test loss = 2.294219\n",
            "Epoch 2: train loss = 2.289447, test loss = 2.283279\n",
            "Epoch 3: train loss = 2.276365, test loss = 2.267052\n",
            "Epoch 4: train loss = 2.256376, test loss = 2.241882\n",
            "Epoch 5: train loss = 2.225171, test loss = 2.202683\n",
            "Epoch 6: train loss = 2.177267, test loss = 2.143544\n",
            "Epoch 7: train loss = 2.107005, test loss = 2.059170\n",
            "Epoch 8: train loss = 2.010345, test loss = 1.946843\n",
            "Epoch 9: train loss = 1.886774, test loss = 1.808589\n",
            "Epoch 10: train loss = 1.741350, test loss = 1.653062\n",
            "Epoch 11: train loss = 1.585487, test loss = 1.494626\n",
            "Epoch 12: train loss = 1.433321, test loss = 1.346681\n",
            "Epoch 13: train loss = 1.295570, test loss = 1.216873\n",
            "Epoch 14: train loss = 1.176615, test loss = 1.106718\n",
            "Epoch 15: train loss = 1.076172, test loss = 1.014386\n",
            "Epoch 16: train loss = 0.991915, test loss = 0.936977\n",
            "Epoch 17: train loss = 0.921062, test loss = 0.871798\n",
            "Epoch 18: train loss = 0.861163, test loss = 0.816605\n",
            "Epoch 19: train loss = 0.810143, test loss = 0.769538\n",
            "Epoch 20: train loss = 0.766413, test loss = 0.728854\n",
            "Epoch 21: train loss = 0.728636, test loss = 0.693747\n",
            "Epoch 22: train loss = 0.695734, test loss = 0.663058\n",
            "Epoch 23: train loss = 0.666925, test loss = 0.636154\n",
            "Epoch 24: train loss = 0.641512, test loss = 0.612143\n",
            "Epoch 25: train loss = 0.618988, test loss = 0.590764\n",
            "Epoch 26: train loss = 0.598855, test loss = 0.571785\n",
            "Epoch 27: train loss = 0.580801, test loss = 0.554742\n",
            "Epoch 28: train loss = 0.564574, test loss = 0.539249\n",
            "Epoch 29: train loss = 0.549835, test loss = 0.525191\n",
            "Epoch 30: train loss = 0.536423, test loss = 0.512296\n",
            "Epoch 31: train loss = 0.524180, test loss = 0.500604\n",
            "Epoch 32: train loss = 0.512984, test loss = 0.489975\n",
            "Epoch 33: train loss = 0.502660, test loss = 0.480016\n",
            "Epoch 34: train loss = 0.493144, test loss = 0.470788\n",
            "Epoch 35: train loss = 0.484325, test loss = 0.462565\n",
            "Epoch 36: train loss = 0.476139, test loss = 0.454885\n",
            "Epoch 37: train loss = 0.468580, test loss = 0.447305\n",
            "Epoch 38: train loss = 0.461484, test loss = 0.440568\n",
            "Epoch 39: train loss = 0.454850, test loss = 0.434336\n",
            "Epoch 40: train loss = 0.448638, test loss = 0.428457\n",
            "Epoch 41: train loss = 0.442809, test loss = 0.422710\n",
            "Epoch 42: train loss = 0.437336, test loss = 0.417415\n",
            "Epoch 43: train loss = 0.432167, test loss = 0.412603\n",
            "Epoch 44: train loss = 0.427279, test loss = 0.407916\n",
            "Epoch 45: train loss = 0.422690, test loss = 0.403587\n",
            "Epoch 46: train loss = 0.418292, test loss = 0.399499\n",
            "Epoch 47: train loss = 0.414172, test loss = 0.395390\n",
            "Epoch 48: train loss = 0.410237, test loss = 0.391724\n",
            "Epoch 49: train loss = 0.406485, test loss = 0.388145\n",
            "Epoch 50: train loss = 0.402923, test loss = 0.384911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot train and test loss as a function of epoch"
      ],
      "metadata": {
        "id": "2CWdkpLpXRmz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Iv3k23SlCqGf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "26c7c864-24d8-4827-81bc-b3ad30b2f9cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "ax.plot(loss_train_epoch, 'b', label = 'Train')\n",
        "ax.plot(loss_test_epoch, 'r', label = 'Test')\n",
        "ax.set_xlabel('Epoch', fontsize = 12)\n",
        "ax.set_ylabel('Loss value', fontsize = 12)\n",
        "ax.legend()\n",
        "ax.set_title('Loss vs. Epoch for reg. strength 0.01', fontsize = 14);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test performance on test data\n",
        "Forward Propagation Using the Weights from the Last Epoch and Predicting the Output Lables for the Test data"
      ],
      "metadata": {
        "id": "0gCpbGyNXX8o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "d7AEbmpcKcPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b4a673-6504-48bf-c67f-9d972b58bb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 2 1 ... 4 5 6]\n",
            "[7 2 1 ... 4 5 6]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8973"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "## Forward propagate using the weights from the last epoch\n",
        "dlayer1.forward(X_test)\n",
        "alayer1.forward(dlayer1.output)\n",
        "dlayer2.forward(alayer1.output)\n",
        "softmax.forward(dlayer2.output)\n",
        "\n",
        "# Predict the output labels for the test data\n",
        "ypred = np.argmax(softmax.output.T, axis = 1)\n",
        "print(ypred)\n",
        "ytrue = np.argmax(Y_test.T, axis = 1)\n",
        "print(ytrue)\n",
        "np.mean(ytrue == ypred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix: Used to know how the model performs on unseen test data\n",
        "* sklearn's metrics module is used to create the confusion matrix\n",
        "* It has a function  called confusion_matrix to create the matrix"
      ],
      "metadata": {
        "id": "AzqhLVr5tzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(ytrue, ypred)"
      ],
      "metadata": {
        "id": "X3FFv71B-fX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fb5b5f-cca5-4954-c009-8bc006f85cb3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 955,    0,    5,    2,    0,    7,    9,    1,    1,    0],\n",
              "       [   0, 1106,    0,    5,    0,    1,    4,    1,   18,    0],\n",
              "       [  13,   11,  891,   17,   19,    1,   20,   16,   42,    2],\n",
              "       [   4,    0,   22,  895,    1,   37,    2,   18,   25,    6],\n",
              "       [   1,    4,    6,    1,  908,    1,   14,    1,    7,   39],\n",
              "       [  18,    3,    6,   52,   12,  722,   25,   10,   35,    9],\n",
              "       [  19,    3,   12,    1,   19,   18,  879,    0,    7,    0],\n",
              "       [   6,   19,   28,    3,    9,    1,    0,  922,    6,   34],\n",
              "       [   6,    9,   14,   27,   13,   35,   14,   11,  825,   20],\n",
              "       [  11,    7,    5,   11,   51,   14,    0,   33,    7,  870]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}