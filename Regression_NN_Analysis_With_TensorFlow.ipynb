{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Load  Python libraries"
      ],
      "metadata": {
        "id": "PIYJfDtjMcB5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dEgRpy3952M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting the printing precision to 2"
      ],
      "metadata": {
        "id": "djPvscl0MioS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G9W_1_v_6yq7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the TensorFlow library and Keras module and Checking Its version"
      ],
      "metadata": {
        "id": "yqavkbLqMmTH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4T7eUtw7Mh0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ec55ac8b-eaf7-452b-a665-87d49bf17ab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbaFOIn_CDuN"
      },
      "source": [
        "### Mount Google Drive if running in Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "02xk1yt7CE1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3665b48e-f570-4686-d9e8-18873fe1c871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16BpVeIWIOks"
      },
      "source": [
        "### Load diabetes dataset using the Pandas library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E5kaKFKSIQgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "2dba2fdb-c80c-40e2-f42c-9a72a06860a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes dataset\n",
            "-----------\n",
            "Initial number of samples = 442\n",
            "Initial number of features = 11\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   AGE  GENDER    BMILEVEL     BP   S1     S2    S3   S4      S5  S6    Y\n",
              "0   59       2   unhealthy  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
              "1   48       1     healthy   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
              "2   72       2   unhealthy   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
              "3   24       1  overweight   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
              "4   50       1     healthy  101.0  192  125.4  52.0  4.0  4.2905  80  135"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4acae2c-096e-4d75-9827-1f8443816454\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGE</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>BMILEVEL</th>\n",
              "      <th>BP</th>\n",
              "      <th>S1</th>\n",
              "      <th>S2</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>S5</th>\n",
              "      <th>S6</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>2</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>101.0</td>\n",
              "      <td>157</td>\n",
              "      <td>93.2</td>\n",
              "      <td>38.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.8598</td>\n",
              "      <td>87</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>healthy</td>\n",
              "      <td>87.0</td>\n",
              "      <td>183</td>\n",
              "      <td>103.2</td>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.8918</td>\n",
              "      <td>69</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>72</td>\n",
              "      <td>2</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>93.0</td>\n",
              "      <td>156</td>\n",
              "      <td>93.6</td>\n",
              "      <td>41.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.6728</td>\n",
              "      <td>85</td>\n",
              "      <td>141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>overweight</td>\n",
              "      <td>84.0</td>\n",
              "      <td>198</td>\n",
              "      <td>131.4</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.8903</td>\n",
              "      <td>89</td>\n",
              "      <td>206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>healthy</td>\n",
              "      <td>101.0</td>\n",
              "      <td>192</td>\n",
              "      <td>125.4</td>\n",
              "      <td>52.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.2905</td>\n",
              "      <td>80</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4acae2c-096e-4d75-9827-1f8443816454')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4acae2c-096e-4d75-9827-1f8443816454 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4acae2c-096e-4d75-9827-1f8443816454');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d193309-0d5d-4cc0-baca-3f4751ece89b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d193309-0d5d-4cc0-baca-3f4751ece89b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d193309-0d5d-4cc0-baca-3f4751ece89b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 442,\n  \"fields\": [\n    {\n      \"column\": \"AGE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 19,\n        \"max\": 79,\n        \"num_unique_values\": 58,\n        \"samples\": [\n          59,\n          23,\n          54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GENDER\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMILEVEL\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"healthy\",\n          \"underweight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.831283419782999,\n        \"min\": 62.0,\n        \"max\": 133.0,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          104.33,\n          102.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34,\n        \"min\": 97,\n        \"max\": 301,\n        \"num_unique_values\": 141,\n        \"samples\": [\n          219,\n          250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.413080969276546,\n        \"min\": 41.6,\n        \"max\": 242.4,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          162.8,\n          160.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.934202154863327,\n        \"min\": 22.0,\n        \"max\": 99.0,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          75.0,\n          93.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2904498966082774,\n        \"min\": 2.0,\n        \"max\": 9.09,\n        \"num_unique_values\": 66,\n        \"samples\": [\n          6.42,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5223905610694907,\n        \"min\": 3.2581,\n        \"max\": 6.107,\n        \"num_unique_values\": 184,\n        \"samples\": [\n          3.8501,\n          4.4067\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"S6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 58,\n        \"max\": 124,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          87,\n          68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77,\n        \"min\": 25,\n        \"max\": 346,\n        \"num_unique_values\": 214,\n        \"samples\": [\n          310,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "## Load diabetes data\n",
        "df= pd.read_csv('/content/drive/MyDrive/Project_Data_Sets/diabetes_regression.csv',\n",
        "                header = 0)\n",
        "\n",
        "print('Diabetes dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(df.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(df.shape[1]))\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separating Categorical and Continuous Featues Using Axis = 1"
      ],
      "metadata": {
        "id": "lcB14SLDN5KJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AJE5ehBOClXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3155258e-45da-4a7b-a51d-e3085ae70340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['GENDER', 'BMILEVEL']\n",
            "['AGE', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'Y']\n"
          ]
        }
      ],
      "source": [
        "## Create lists of ordinal, categorical, and continuous features\n",
        "categorical_features =  ['GENDER', 'BMILEVEL']\n",
        "#categorical_features =  ['GENDER']\n",
        "continuous_features = df.drop(categorical_features, axis = 1).columns.tolist()\n",
        "print(categorical_features)\n",
        "print(continuous_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3NyP_EoDG1i"
      },
      "source": [
        "### Changing the dtype of Categorical variables to 'category'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-dVFfOBlDJ5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6080744c-654a-42e1-b576-0b3544da2e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------Before Changing--------------------------\n",
            "AGE           int64\n",
            "GENDER        int64\n",
            "BMILEVEL     object\n",
            "BP          float64\n",
            "S1            int64\n",
            "S2          float64\n",
            "S3          float64\n",
            "S4          float64\n",
            "S5          float64\n",
            "S6            int64\n",
            "Y             int64\n",
            "dtype: object\n",
            "----------------------After Changing---------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AGE            int64\n",
              "GENDER      category\n",
              "BMILEVEL    category\n",
              "BP           float64\n",
              "S1             int64\n",
              "S2           float64\n",
              "S3           float64\n",
              "S4           float64\n",
              "S5           float64\n",
              "S6             int64\n",
              "Y              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print('----------------------Before Changing--------------------------')\n",
        "print(df.dtypes)\n",
        "df[categorical_features] = df[categorical_features].astype('category')\n",
        "print('----------------------After Changing---------------------------')\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95YNt2eDUJ8"
      },
      "source": [
        "### Remove the target variable column ('Y') from the list of continuous features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XuQGzpefDUqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11dd0a0-ed73-4de1-d0da-1879ee863b07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AGE', 'BP', 'S1', 'S2', 'S3', 'S4', 'S5', 'S6']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "## Remove the target variable column from the list of continuous features\n",
        "continuous_features.remove('Y')\n",
        "continuous_features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Tesr Splitting Using Sklearn's train_test_split module and here a 80-20 split is used"
      ],
      "metadata": {
        "id": "ib5SAmq1OvjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tn-qjRocE8Lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d8461e-2a94-4643-8757-926e2d3d00a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes data set\n",
            "---------------------\n",
            "Number of training samples = 10\n",
            "Number of features = 353\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('Y', axis = 1) # This is the Independent variable part\n",
        "y = df['Y'] # This is the dependent variable part\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2,\n",
        "                                                    random_state = 1)\n",
        "\n",
        "num_features = X_train.shape[0]\n",
        "num_samples = X_train.shape[1]\n",
        "\n",
        "print('Diabetes data set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKqSu9e7G-fh"
      },
      "source": [
        "### Build pipeline for categorical and continuous features and Scaling them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FKAqkz1GHGvm"
      },
      "outputs": [],
      "source": [
        "# Pipeline object for categorical (features\n",
        "categorical_transformer = Pipeline(steps = [('onehotenc', OneHotEncoder(handle_unknown = 'ignore'))])\n",
        "\n",
        "# Pipeline object for continuous features\n",
        "continuous_transformer = Pipeline(steps = [('scaler', RobustScaler())])\n",
        "\n",
        "# Create a preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('continuous', continuous_transformer, continuous_features),\n",
        "                                                 ('categorical', categorical_transformer, categorical_features)\n",
        "                                                ],\n",
        "                                 remainder = 'passthrough'\n",
        "                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWWGe-uRPfur"
      },
      "source": [
        "### Apply preprocessor (fit and transform) to train data followed by transform to test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RvrUIw4SHzO_"
      },
      "outputs": [],
      "source": [
        "## Fit and transform train data using preprocessor\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Transform test data using preprocessor\n",
        "X_test_transformed = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfbydCWNOfWj"
      },
      "source": [
        "### Define neural network architecture for regression (3 layer NN; 8 nodes, 8 nodes followed by 1 node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JKVA8gqyOhsx"
      },
      "outputs": [],
      "source": [
        "# Define 3 layer neural network architecture\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation='relu', input_shape=(X_train_transformed.shape[1], ),\n",
        "                 kernel_regularizer = keras.regularizers.l2(l=0.1)), # First Hidden Layer Dense + Activation\n",
        "    layers.Dense(8,kernel_regularizer = keras.regularizers.l2(l=0.1)), # Second Hidden Layer\n",
        "    layers.Dense(1, kernel_regularizer = keras.regularizers.l2(l=0.1))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile the neural network model\n"
      ],
      "metadata": {
        "id": "txV6P61rTa9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mWDSNSXMIyly"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-04)\n",
        "model.compile(optimizer = opt , loss = 'mean_squared_error')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "VMk-aiyvThWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b7prUjNlI0zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d18f30e-a6fd-4410-84d9-fbea6a785371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 2s 22ms/step - loss: 29704.6230 - val_loss: 27065.8730\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29695.0586 - val_loss: 27057.8535\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29685.9746 - val_loss: 27049.7676\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29676.5859 - val_loss: 27041.7227\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29667.2832 - val_loss: 27033.5957\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29657.7500 - val_loss: 27025.0176\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29648.4004 - val_loss: 27016.9043\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29638.9199 - val_loss: 27008.8320\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29629.8164 - val_loss: 27000.7812\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29620.6934 - val_loss: 26992.8867\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29611.5020 - val_loss: 26984.5781\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29601.9121 - val_loss: 26976.3516\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 29592.8164 - val_loss: 26968.1660\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29583.5840 - val_loss: 26959.8672\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29574.0625 - val_loss: 26951.4180\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29564.4609 - val_loss: 26943.4551\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29555.1836 - val_loss: 26934.9941\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29545.5977 - val_loss: 26926.5703\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29535.8418 - val_loss: 26917.6680\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29525.3652 - val_loss: 26908.4219\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29515.4336 - val_loss: 26900.0625\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29505.6914 - val_loss: 26891.3535\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29496.0898 - val_loss: 26883.2129\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29487.1562 - val_loss: 26875.1035\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29477.9375 - val_loss: 26866.5684\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29468.1582 - val_loss: 26857.8418\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29457.8477 - val_loss: 26848.5625\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29447.3906 - val_loss: 26839.3984\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29437.4961 - val_loss: 26830.8184\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29428.0293 - val_loss: 26822.3418\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 29418.5410 - val_loss: 26813.7754\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29409.1504 - val_loss: 26805.3008\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29399.6660 - val_loss: 26796.9668\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29390.2129 - val_loss: 26788.5879\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29380.5703 - val_loss: 26779.4727\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29370.4902 - val_loss: 26770.6074\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29360.7422 - val_loss: 26761.5957\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29350.1074 - val_loss: 26751.8730\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29339.6680 - val_loss: 26742.7070\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29329.4922 - val_loss: 26733.4609\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29318.9980 - val_loss: 26724.0820\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29307.6973 - val_loss: 26713.6348\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29296.6094 - val_loss: 26704.0000\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29285.9434 - val_loss: 26694.6523\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29275.6211 - val_loss: 26685.0391\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29264.8301 - val_loss: 26675.0898\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29253.3652 - val_loss: 26665.2637\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29241.9688 - val_loss: 26654.3125\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29230.1016 - val_loss: 26643.9727\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29217.7676 - val_loss: 26632.7188\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29205.5488 - val_loss: 26621.3281\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29193.0684 - val_loss: 26610.8594\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29181.5996 - val_loss: 26600.6934\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29170.0938 - val_loss: 26589.7812\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29157.9043 - val_loss: 26579.2227\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29146.4023 - val_loss: 26568.4609\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 29134.2090 - val_loss: 26557.6660\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29121.9355 - val_loss: 26546.1016\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29108.8320 - val_loss: 26534.6621\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29096.2656 - val_loss: 26523.4297\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29083.7871 - val_loss: 26512.2422\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29071.2148 - val_loss: 26500.6230\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29058.3906 - val_loss: 26489.1738\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29045.4766 - val_loss: 26476.9160\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29031.9316 - val_loss: 26465.3223\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 29018.9746 - val_loss: 26453.3223\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 29005.3379 - val_loss: 26440.7871\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28991.2695 - val_loss: 26428.3281\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28977.4277 - val_loss: 26415.9551\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28963.4043 - val_loss: 26402.8652\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28948.9238 - val_loss: 26390.4121\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28935.0430 - val_loss: 26377.9883\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28920.9863 - val_loss: 26365.2031\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28906.4102 - val_loss: 26352.2383\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28891.8223 - val_loss: 26338.8125\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28877.0938 - val_loss: 26325.4863\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28861.6484 - val_loss: 26311.4492\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28845.7715 - val_loss: 26297.6523\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28829.3281 - val_loss: 26282.3926\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28812.7441 - val_loss: 26267.3828\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28796.2031 - val_loss: 26253.4551\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28780.8926 - val_loss: 26239.4102\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 28765.0371 - val_loss: 26225.5176\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28749.5332 - val_loss: 26211.3594\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28733.9141 - val_loss: 26196.8926\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28717.1055 - val_loss: 26182.2578\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28700.3848 - val_loss: 26166.4609\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28682.7812 - val_loss: 26150.5898\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28665.4219 - val_loss: 26135.3340\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28647.8887 - val_loss: 26119.6660\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28629.9863 - val_loss: 26103.5254\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28611.6094 - val_loss: 26086.9160\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28593.3574 - val_loss: 26071.2559\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28575.9746 - val_loss: 26055.0273\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28556.2949 - val_loss: 26036.9883\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28535.2383 - val_loss: 26017.8262\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28513.8867 - val_loss: 25999.4434\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28492.9121 - val_loss: 25980.7363\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28472.9434 - val_loss: 25963.6914\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28453.7031 - val_loss: 25946.4043\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28433.9258 - val_loss: 25928.3965\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28413.2637 - val_loss: 25909.7871\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28393.1133 - val_loss: 25891.7500\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28372.1582 - val_loss: 25873.8906\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28352.8301 - val_loss: 25855.8867\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28331.3652 - val_loss: 25835.7520\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28308.9355 - val_loss: 25816.6152\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28287.7246 - val_loss: 25797.1230\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28266.1152 - val_loss: 25777.6582\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 28243.0449 - val_loss: 25757.0625\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28221.0254 - val_loss: 25737.3457\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28198.7598 - val_loss: 25718.5371\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28177.7754 - val_loss: 25699.6074\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28156.9512 - val_loss: 25680.4277\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28134.9980 - val_loss: 25661.5977\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28113.4668 - val_loss: 25641.5430\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 28091.3164 - val_loss: 25621.4297\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28067.8301 - val_loss: 25600.9160\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 28045.6523 - val_loss: 25580.2578\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 28021.3379 - val_loss: 25558.4160\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 27996.9863 - val_loss: 25537.0332\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 27973.5781 - val_loss: 25515.5430\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 27949.4043 - val_loss: 25493.7637\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 27924.5430 - val_loss: 25471.6992\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27899.5137 - val_loss: 25449.3984\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27874.3164 - val_loss: 25426.1367\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27848.2012 - val_loss: 25403.0449\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27822.9102 - val_loss: 25380.3574\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27796.8750 - val_loss: 25357.7520\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27771.7715 - val_loss: 25334.8652\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27746.1387 - val_loss: 25311.6582\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27720.0684 - val_loss: 25288.5176\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27693.7910 - val_loss: 25264.5449\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27665.9766 - val_loss: 25239.6230\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27637.8945 - val_loss: 25215.3926\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 27610.8008 - val_loss: 25190.8652\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27582.7285 - val_loss: 25165.4434\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27553.7988 - val_loss: 25140.0273\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27524.6035 - val_loss: 25113.6406\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27494.9121 - val_loss: 25087.7363\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27464.7402 - val_loss: 25060.5020\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27435.0996 - val_loss: 25033.3516\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27403.5332 - val_loss: 25006.0957\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27373.4004 - val_loss: 24978.5391\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27341.4297 - val_loss: 24950.8867\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27308.8008 - val_loss: 24920.0879\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27274.0449 - val_loss: 24890.2168\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27239.5703 - val_loss: 24859.9980\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27206.1719 - val_loss: 24831.4883\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27174.3848 - val_loss: 24802.3516\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27140.2910 - val_loss: 24772.1523\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 27105.9609 - val_loss: 24742.6602\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27072.2949 - val_loss: 24711.9805\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 27037.8184 - val_loss: 24681.2617\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27000.6836 - val_loss: 24647.4980\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26961.6660 - val_loss: 24613.5840\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26924.0312 - val_loss: 24580.4531\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26885.7559 - val_loss: 24547.9219\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26846.1309 - val_loss: 24512.2520\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26807.7227 - val_loss: 24478.6172\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26770.2402 - val_loss: 24446.2188\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26733.9414 - val_loss: 24413.8633\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26696.8320 - val_loss: 24381.4023\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26657.4570 - val_loss: 24344.0312\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26616.8438 - val_loss: 24309.9277\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 26578.3320 - val_loss: 24276.4043\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26537.7402 - val_loss: 24240.2734\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26495.1445 - val_loss: 24202.1406\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 26453.0898 - val_loss: 24166.1016\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26411.5234 - val_loss: 24130.0059\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26370.6738 - val_loss: 24094.7051\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 26330.7285 - val_loss: 24058.5176\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26288.8730 - val_loss: 24020.3125\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26244.3027 - val_loss: 23981.4609\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 26199.2500 - val_loss: 23942.9805\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26156.5918 - val_loss: 23905.4551\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 26112.3145 - val_loss: 23866.8418\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26069.1211 - val_loss: 23829.4941\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 26025.7598 - val_loss: 23791.1230\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25982.1758 - val_loss: 23751.6289\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25937.2344 - val_loss: 23714.0840\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25893.7188 - val_loss: 23674.8926\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25849.9199 - val_loss: 23634.3906\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25803.5996 - val_loss: 23595.5430\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25758.0000 - val_loss: 23554.8770\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25709.3516 - val_loss: 23510.7734\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25659.0547 - val_loss: 23463.9883\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25607.0293 - val_loss: 23423.3066\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25561.1309 - val_loss: 23383.1152\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25515.0547 - val_loss: 23342.9863\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25466.9199 - val_loss: 23297.6777\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25415.6055 - val_loss: 23256.0742\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25368.8691 - val_loss: 23212.5566\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25319.4961 - val_loss: 23170.7637\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25271.9570 - val_loss: 23129.7676\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25225.6113 - val_loss: 23087.9375\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25177.1074 - val_loss: 23045.0469\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 25127.9141 - val_loss: 23001.7500\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 25077.8730 - val_loss: 22957.4316\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 25024.2598 - val_loss: 22909.5078\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24971.0801 - val_loss: 22862.9570\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24919.4531 - val_loss: 22816.5273\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24865.1133 - val_loss: 22770.6172\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24814.0742 - val_loss: 22724.9863\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24759.9863 - val_loss: 22678.8457\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24706.1152 - val_loss: 22629.4297\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24646.2832 - val_loss: 22576.8672\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24589.0312 - val_loss: 22529.4883\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24535.3027 - val_loss: 22483.1523\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24482.3438 - val_loss: 22436.6133\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24430.2148 - val_loss: 22389.9277\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24376.6523 - val_loss: 22343.9766\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24323.6523 - val_loss: 22296.4766\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24268.6094 - val_loss: 22248.2969\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 24214.0488 - val_loss: 22200.4688\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24158.7852 - val_loss: 22151.6426\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24101.3789 - val_loss: 22102.0527\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 24042.9258 - val_loss: 22050.1211\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23985.3066 - val_loss: 22000.7578\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23928.7676 - val_loss: 21952.6152\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23873.0938 - val_loss: 21903.9082\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23817.5273 - val_loss: 21853.4082\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 23759.7207 - val_loss: 21803.4805\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23701.8379 - val_loss: 21751.6426\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23638.8008 - val_loss: 21693.1484\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23572.3945 - val_loss: 21636.4258\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 23506.7109 - val_loss: 21578.0332\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23441.0020 - val_loss: 21525.7480\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23381.4668 - val_loss: 21470.4844\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23316.4863 - val_loss: 21415.6426\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23254.9824 - val_loss: 21362.8184\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23196.6367 - val_loss: 21310.1016\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 23131.9082 - val_loss: 21253.5840\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 23065.5918 - val_loss: 21193.1250\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22995.5020 - val_loss: 21134.4238\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22931.4238 - val_loss: 21080.4785\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22870.3320 - val_loss: 21027.7324\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22809.6875 - val_loss: 20974.3086\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22749.2910 - val_loss: 20919.0176\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 22684.3164 - val_loss: 20863.8125\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22620.9043 - val_loss: 20807.4727\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22557.1719 - val_loss: 20753.7188\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22495.4238 - val_loss: 20699.8223\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22433.7129 - val_loss: 20646.3125\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22373.0918 - val_loss: 20591.5840\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22309.4590 - val_loss: 20537.2246\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 22248.0801 - val_loss: 20483.5156\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22186.4648 - val_loss: 20428.7070\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22123.6191 - val_loss: 20371.4688\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22054.5547 - val_loss: 20311.0840\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21987.3594 - val_loss: 20253.1328\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21919.6426 - val_loss: 20190.7754\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21843.8047 - val_loss: 20124.8027\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21769.6758 - val_loss: 20063.9238\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21702.9238 - val_loss: 20006.8828\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21635.9746 - val_loss: 19945.8516\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21566.5156 - val_loss: 19889.5449\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21503.9902 - val_loss: 19832.4277\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21437.3574 - val_loss: 19771.9512\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21367.3828 - val_loss: 19711.6680\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21299.3652 - val_loss: 19655.7461\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21234.4590 - val_loss: 19597.5254\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 21166.5488 - val_loss: 19538.1230\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21100.7559 - val_loss: 19480.9219\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 21034.2305 - val_loss: 19422.7344\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20969.1055 - val_loss: 19365.1094\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 20901.7969 - val_loss: 19306.4766\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20834.2852 - val_loss: 19246.2461\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20764.2910 - val_loss: 19185.6875\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20695.5586 - val_loss: 19127.2617\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 20626.3281 - val_loss: 19062.9844\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 20555.1680 - val_loss: 19003.9395\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 20485.5996 - val_loss: 18942.4121\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 20416.5488 - val_loss: 18881.9004\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 20348.2969 - val_loss: 18824.0078\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 20280.8242 - val_loss: 18765.7773\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 20211.0039 - val_loss: 18701.6484\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 20137.5000 - val_loss: 18637.0273\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 20066.2090 - val_loss: 18577.0195\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19995.4062 - val_loss: 18515.5254\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19924.8379 - val_loss: 18454.5898\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 19856.0664 - val_loss: 18395.5273\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 19787.8125 - val_loss: 18336.0117\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19720.2285 - val_loss: 18277.2812\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19651.3574 - val_loss: 18218.1484\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19584.7812 - val_loss: 18157.2266\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19512.4883 - val_loss: 18091.8672\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19438.7500 - val_loss: 18028.6797\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19364.7734 - val_loss: 17966.8066\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19293.6211 - val_loss: 17903.1797\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 19220.8848 - val_loss: 17837.2441\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19147.3535 - val_loss: 17775.8379\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 19075.3789 - val_loss: 17713.7070\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 19004.4902 - val_loss: 17647.4121\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18922.3242 - val_loss: 17575.3418\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18839.5957 - val_loss: 17504.6504\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18764.5879 - val_loss: 17441.6270\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 18693.0332 - val_loss: 17382.6758\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18625.7012 - val_loss: 17322.9570\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 18557.7227 - val_loss: 17262.9375\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 18487.4707 - val_loss: 17200.3223\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 18417.6387 - val_loss: 17138.6367\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 18345.0176 - val_loss: 17074.0566\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18269.1738 - val_loss: 17004.5820\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18192.3848 - val_loss: 16941.4980\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 18116.5410 - val_loss: 16873.1680\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 18040.9043 - val_loss: 16811.4629\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17970.1523 - val_loss: 16747.7773\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 17899.4707 - val_loss: 16687.3164\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17829.7773 - val_loss: 16627.1016\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17762.2422 - val_loss: 16567.2051\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 17693.0664 - val_loss: 16508.1934\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 17625.2910 - val_loss: 16448.4473\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 17550.7695 - val_loss: 16380.5361\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17475.8457 - val_loss: 16314.5742\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17401.2441 - val_loss: 16248.0547\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17324.7422 - val_loss: 16184.7041\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17248.5078 - val_loss: 16114.5059\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 17169.5156 - val_loss: 16050.1572\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 17100.0977 - val_loss: 15987.5156\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17027.0312 - val_loss: 15923.9805\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16952.4668 - val_loss: 15856.7598\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16878.0703 - val_loss: 15795.3877\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16808.6367 - val_loss: 15737.5137\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16744.0371 - val_loss: 15677.1240\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16673.8965 - val_loss: 15619.1914\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16607.5020 - val_loss: 15559.5264\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16538.8164 - val_loss: 15499.2041\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16468.2695 - val_loss: 15435.5361\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16396.3203 - val_loss: 15374.8877\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 16322.8926 - val_loss: 15308.3086\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16248.0225 - val_loss: 15244.7861\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16177.7822 - val_loss: 15182.8037\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 16104.6230 - val_loss: 15116.6211\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16027.9873 - val_loss: 15049.8711\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15954.7871 - val_loss: 14988.7725\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15884.4873 - val_loss: 14927.3213\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15810.8232 - val_loss: 14859.0098\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15734.5557 - val_loss: 14798.4268\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15666.9307 - val_loss: 14737.3838\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15591.5918 - val_loss: 14669.3115\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15515.5400 - val_loss: 14605.1436\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15444.0977 - val_loss: 14545.2617\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15376.9902 - val_loss: 14486.0410\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15308.7676 - val_loss: 14426.1768\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15241.0947 - val_loss: 14367.5908\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15172.6914 - val_loss: 14309.4434\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 15107.4395 - val_loss: 14249.2822\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15039.0166 - val_loss: 14189.5635\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14970.9395 - val_loss: 14129.7217\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14903.6689 - val_loss: 14070.8486\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14836.0059 - val_loss: 14013.1855\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14768.3154 - val_loss: 13948.9863\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14692.1504 - val_loss: 13881.7383\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14618.5850 - val_loss: 13820.3594\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14544.6348 - val_loss: 13754.9814\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14470.4033 - val_loss: 13692.1602\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14400.0195 - val_loss: 13630.7500\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14331.1865 - val_loss: 13571.8008\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14261.8545 - val_loss: 13510.1377\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14193.2930 - val_loss: 13452.0254\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14128.4648 - val_loss: 13393.7539\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 14062.8262 - val_loss: 13335.6094\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13995.3682 - val_loss: 13276.9609\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 13928.8936 - val_loss: 13219.8682\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13859.5449 - val_loss: 13156.8916\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13790.3516 - val_loss: 13098.0771\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13716.8398 - val_loss: 13030.7236\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13644.8809 - val_loss: 12971.2822\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13576.6768 - val_loss: 12911.1992\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13509.6514 - val_loss: 12850.4072\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13436.6514 - val_loss: 12784.9766\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 13365.9287 - val_loss: 12726.5684\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13296.1064 - val_loss: 12665.5186\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 13226.6543 - val_loss: 12599.8242\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13147.9678 - val_loss: 12536.7656\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13080.1953 - val_loss: 12479.3779\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13014.9316 - val_loss: 12422.4717\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12951.2139 - val_loss: 12365.5840\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12883.6348 - val_loss: 12304.5986\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 12816.3711 - val_loss: 12247.8311\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12754.2832 - val_loss: 12190.8760\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12684.5039 - val_loss: 12127.0098\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12614.4775 - val_loss: 12068.0391\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12549.0449 - val_loss: 12014.4355\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 12490.0713 - val_loss: 11960.4619\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12428.4023 - val_loss: 11905.3975\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12366.4521 - val_loss: 11851.2344\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 12305.1201 - val_loss: 11798.0996\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12246.3262 - val_loss: 11744.4434\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12185.0908 - val_loss: 11691.8291\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 12125.7168 - val_loss: 11639.3555\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12067.2988 - val_loss: 11587.0811\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12006.9502 - val_loss: 11534.1689\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11947.9990 - val_loss: 11480.5264\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11882.5762 - val_loss: 11422.5557\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11821.0811 - val_loss: 11368.2793\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11757.0273 - val_loss: 11310.7666\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11694.5449 - val_loss: 11257.4971\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11635.2051 - val_loss: 11205.1387\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11577.0312 - val_loss: 11153.7363\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11515.5791 - val_loss: 11098.9717\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11458.4961 - val_loss: 11049.2891\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11398.0400 - val_loss: 10993.9238\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11334.4863 - val_loss: 10939.6514\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11276.9307 - val_loss: 10888.3711\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11218.3857 - val_loss: 10834.5107\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11158.5674 - val_loss: 10782.4072\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11100.5215 - val_loss: 10729.8643\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 11038.3076 - val_loss: 10672.4414\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10976.1289 - val_loss: 10622.0830\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10918.8623 - val_loss: 10570.6689\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10862.4766 - val_loss: 10519.3564\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10802.5371 - val_loss: 10466.1543\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10744.7334 - val_loss: 10417.4951\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10690.4902 - val_loss: 10369.3477\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10635.5322 - val_loss: 10319.5771\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10580.8281 - val_loss: 10271.3867\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10525.3838 - val_loss: 10221.9307\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10468.1592 - val_loss: 10169.7168\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10410.6914 - val_loss: 10119.2188\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10354.2256 - val_loss: 10065.0176\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10292.3965 - val_loss: 10011.3896\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10234.7168 - val_loss: 9963.4590\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10181.1025 - val_loss: 9915.9033\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10129.1387 - val_loss: 9869.8613\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10074.0361 - val_loss: 9818.5312\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 10013.8594 - val_loss: 9764.0586\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9958.2480 - val_loss: 9718.4609\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9907.2461 - val_loss: 9674.9170\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 9858.9219 - val_loss: 9631.6465\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9811.2607 - val_loss: 9588.1533\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9762.6816 - val_loss: 9547.8066\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9718.7959 - val_loss: 9508.0098\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9673.8477 - val_loss: 9465.9033\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9625.3242 - val_loss: 9423.9648\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9579.5703 - val_loss: 9380.5498\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9530.5908 - val_loss: 9337.2539\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9483.6689 - val_loss: 9293.5166\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9431.2939 - val_loss: 9245.3096\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9374.4961 - val_loss: 9195.9072\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9319.9336 - val_loss: 9146.2959\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9265.7412 - val_loss: 9100.3867\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9215.6660 - val_loss: 9058.1709\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 9166.3828 - val_loss: 9012.5029\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9118.6982 - val_loss: 8968.3154\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9071.6035 - val_loss: 8929.0752\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9029.9971 - val_loss: 8894.4004\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8988.2002 - val_loss: 8851.1768\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8938.9111 - val_loss: 8806.6084\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8889.9678 - val_loss: 8764.4854\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8845.5469 - val_loss: 8725.2041\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8800.2627 - val_loss: 8683.5898\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8754.2588 - val_loss: 8643.2002\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8708.0107 - val_loss: 8599.4990\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8661.1719 - val_loss: 8557.5986\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8612.2480 - val_loss: 8511.7588\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8564.3467 - val_loss: 8472.7041\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8525.1357 - val_loss: 8437.6211\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8484.2568 - val_loss: 8400.4160\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8444.5107 - val_loss: 8365.5762\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8406.1514 - val_loss: 8328.7930\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8364.9160 - val_loss: 8290.0684\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8319.8008 - val_loss: 8251.0156\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8279.9111 - val_loss: 8212.3008\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8234.4395 - val_loss: 8170.4204\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8189.7500 - val_loss: 8130.9858\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8147.2905 - val_loss: 8094.2866\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8102.9639 - val_loss: 8051.7515\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8059.0894 - val_loss: 8014.2642\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8015.3306 - val_loss: 7974.6313\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7975.3506 - val_loss: 7939.6445\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7937.0552 - val_loss: 7905.4282\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7900.5000 - val_loss: 7872.9312\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7865.3384 - val_loss: 7839.6216\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7829.1270 - val_loss: 7806.7441\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7789.9385 - val_loss: 7769.1567\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7750.0225 - val_loss: 7736.7881\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7715.1001 - val_loss: 7701.8638\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7675.1978 - val_loss: 7663.8652\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7637.7954 - val_loss: 7632.9531\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7603.9287 - val_loss: 7601.7969\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7567.3008 - val_loss: 7566.2744\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7529.8667 - val_loss: 7530.6992\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7490.0425 - val_loss: 7494.9697\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7453.2300 - val_loss: 7463.7632\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7420.3242 - val_loss: 7432.6235\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7382.6978 - val_loss: 7396.2095\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7344.4575 - val_loss: 7364.3730\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7307.8589 - val_loss: 7329.0757\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7270.6631 - val_loss: 7296.4790\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7235.2607 - val_loss: 7264.8979\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7202.5000 - val_loss: 7233.3442\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7168.7285 - val_loss: 7204.3032\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7139.0356 - val_loss: 7177.7031\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7109.8174 - val_loss: 7149.7627\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7080.3208 - val_loss: 7123.1572\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7052.3916 - val_loss: 7096.8623\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7023.8433 - val_loss: 7069.6309\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6992.0552 - val_loss: 7039.2329\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 6960.4751 - val_loss: 7011.1621\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6932.2090 - val_loss: 6984.7754\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6903.1860 - val_loss: 6957.8960\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6874.8145 - val_loss: 6930.8506\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6847.1260 - val_loss: 6906.6729\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6818.7134 - val_loss: 6878.0737\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6788.2485 - val_loss: 6850.4204\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6759.7930 - val_loss: 6824.0366\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6728.9902 - val_loss: 6794.9292\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6698.4556 - val_loss: 6768.4780\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6669.5298 - val_loss: 6739.7441\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6640.5278 - val_loss: 6714.5659\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6614.5757 - val_loss: 6691.6816\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6589.6655 - val_loss: 6667.9902\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6564.3770 - val_loss: 6642.4517\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6538.1641 - val_loss: 6617.9155\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6509.2988 - val_loss: 6590.8354\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6480.4810 - val_loss: 6563.0767\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6450.3599 - val_loss: 6534.9780\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6421.3408 - val_loss: 6507.3906\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6394.2939 - val_loss: 6483.6362\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6366.0786 - val_loss: 6453.8394\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6334.4517 - val_loss: 6426.3569\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6303.9688 - val_loss: 6397.5308\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6276.0713 - val_loss: 6374.3994\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6251.0190 - val_loss: 6348.7261\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6224.1460 - val_loss: 6322.0659\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6196.5674 - val_loss: 6296.1714\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6172.0679 - val_loss: 6273.0117\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6148.0522 - val_loss: 6250.2197\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6122.8662 - val_loss: 6227.0884\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6103.8149 - val_loss: 6212.4756\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6086.2847 - val_loss: 6194.2246\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 6066.8823 - val_loss: 6173.2671\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6041.8257 - val_loss: 6148.9644\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6018.5942 - val_loss: 6127.6279\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5997.1997 - val_loss: 6107.9468\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5976.7725 - val_loss: 6088.7866\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5956.6460 - val_loss: 6069.4033\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5936.7744 - val_loss: 6050.4888\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5916.8047 - val_loss: 6032.2002\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5896.6714 - val_loss: 6011.8945\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5875.4800 - val_loss: 5990.6235\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5853.7432 - val_loss: 5969.6943\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5834.6162 - val_loss: 5953.2451\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5816.7617 - val_loss: 5935.7021\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5797.7686 - val_loss: 5915.9531\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5776.6064 - val_loss: 5896.2710\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5757.4429 - val_loss: 5878.4512\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5739.0024 - val_loss: 5860.5518\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5720.7856 - val_loss: 5843.3999\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5701.7354 - val_loss: 5826.2275\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5688.3149 - val_loss: 5813.7056\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5671.4648 - val_loss: 5795.3721\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5652.5532 - val_loss: 5778.1025\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5634.2798 - val_loss: 5760.5112\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5617.3535 - val_loss: 5744.6558\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5600.3472 - val_loss: 5729.0708\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5584.2334 - val_loss: 5712.5000\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5565.4531 - val_loss: 5693.0771\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5544.3496 - val_loss: 5673.9409\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5527.7749 - val_loss: 5657.6504\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5510.5679 - val_loss: 5640.2129\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5493.4917 - val_loss: 5622.9868\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5475.8496 - val_loss: 5606.9785\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5458.0532 - val_loss: 5588.5854\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5442.1694 - val_loss: 5573.5332\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5425.4580 - val_loss: 5557.3657\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5409.6958 - val_loss: 5541.5747\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5392.7822 - val_loss: 5523.5112\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5375.6963 - val_loss: 5508.3794\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5359.5410 - val_loss: 5492.9468\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5343.2544 - val_loss: 5475.1694\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5325.6440 - val_loss: 5460.3154\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5311.2227 - val_loss: 5443.9707\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5293.2241 - val_loss: 5429.4800\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5279.2158 - val_loss: 5414.0288\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5263.4673 - val_loss: 5400.0527\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5249.6206 - val_loss: 5386.0830\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5235.2446 - val_loss: 5371.5269\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5220.6182 - val_loss: 5357.7749\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5206.7817 - val_loss: 5343.9482\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5192.1143 - val_loss: 5328.8926\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5176.5923 - val_loss: 5313.7026\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5160.7266 - val_loss: 5299.5190\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5146.4106 - val_loss: 5283.8926\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5130.5088 - val_loss: 5269.4658\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5116.6064 - val_loss: 5255.7134\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5102.7686 - val_loss: 5242.5742\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5090.6455 - val_loss: 5231.6172\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5078.4224 - val_loss: 5219.5063\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5063.8560 - val_loss: 5203.4531\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5046.0327 - val_loss: 5186.1733\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5029.4634 - val_loss: 5170.6792\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 5014.7861 - val_loss: 5155.9912\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5000.3037 - val_loss: 5143.0894\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4988.2686 - val_loss: 5131.9429\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4977.6519 - val_loss: 5121.7402\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4965.4478 - val_loss: 5109.4395\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4952.3994 - val_loss: 5096.3481\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4938.8188 - val_loss: 5080.3931\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4923.4595 - val_loss: 5065.3652\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4909.1714 - val_loss: 5053.9604\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4898.5518 - val_loss: 5043.4434\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4886.9707 - val_loss: 5031.0371\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4873.4854 - val_loss: 5016.9741\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4860.7593 - val_loss: 5004.7744\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4848.3306 - val_loss: 4993.4331\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4837.0762 - val_loss: 4982.1245\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4823.9814 - val_loss: 4969.5776\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4812.8486 - val_loss: 4958.4697\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4801.9033 - val_loss: 4946.3999\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4790.0151 - val_loss: 4935.4248\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4777.5425 - val_loss: 4922.3970\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4765.5479 - val_loss: 4911.3701\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4754.8691 - val_loss: 4901.2231\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4744.7744 - val_loss: 4891.7573\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4734.4092 - val_loss: 4880.8364\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4722.9438 - val_loss: 4868.7407\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4710.2490 - val_loss: 4856.2544\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4698.4287 - val_loss: 4844.1089\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4686.2183 - val_loss: 4833.6221\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4675.8848 - val_loss: 4823.6553\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4665.3936 - val_loss: 4814.0684\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4654.7251 - val_loss: 4803.0605\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4644.0869 - val_loss: 4793.4053\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4634.0640 - val_loss: 4783.3594\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4622.0820 - val_loss: 4771.2393\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4607.6245 - val_loss: 4756.1060\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4593.2891 - val_loss: 4743.8823\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4583.3184 - val_loss: 4734.5645\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4574.5796 - val_loss: 4727.5645\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4566.4106 - val_loss: 4719.6016\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4556.4673 - val_loss: 4708.2056\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4544.9502 - val_loss: 4697.4873\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4534.9585 - val_loss: 4687.8579\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4525.4526 - val_loss: 4679.3320\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4516.9434 - val_loss: 4671.9761\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4508.6206 - val_loss: 4663.5781\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4499.8594 - val_loss: 4653.8140\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4488.2998 - val_loss: 4641.8394\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4476.1592 - val_loss: 4629.8096\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4464.1694 - val_loss: 4619.2407\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4453.1152 - val_loss: 4608.7812\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4444.1616 - val_loss: 4599.3193\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4432.7656 - val_loss: 4588.0703\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4421.1147 - val_loss: 4576.5752\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4410.3428 - val_loss: 4567.1792\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4401.3955 - val_loss: 4558.7441\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4392.2837 - val_loss: 4547.9697\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4383.7222 - val_loss: 4540.8345\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4375.6030 - val_loss: 4532.7598\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4366.9180 - val_loss: 4523.4546\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4358.5801 - val_loss: 4516.6099\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4350.1089 - val_loss: 4507.4243\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4341.3569 - val_loss: 4498.6558\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4331.9263 - val_loss: 4488.7969\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4321.6294 - val_loss: 4479.6089\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4312.9756 - val_loss: 4471.4653\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4305.0127 - val_loss: 4463.4971\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4296.8184 - val_loss: 4454.9629\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4288.3281 - val_loss: 4446.1143\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4279.9458 - val_loss: 4437.9458\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4271.7661 - val_loss: 4429.6758\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4263.8369 - val_loss: 4421.9614\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4255.9595 - val_loss: 4414.7646\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4249.0894 - val_loss: 4408.2051\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4241.5972 - val_loss: 4398.9692\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4230.6846 - val_loss: 4387.0317\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4221.6436 - val_loss: 4379.7271\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4213.5640 - val_loss: 4371.6553\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4205.5942 - val_loss: 4363.5317\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4197.1338 - val_loss: 4354.7661\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4189.1738 - val_loss: 4348.0132\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4182.5293 - val_loss: 4341.5718\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4172.8896 - val_loss: 4330.5757\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4162.2456 - val_loss: 4320.9312\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4153.9551 - val_loss: 4313.4077\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4147.1104 - val_loss: 4306.1689\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4139.7490 - val_loss: 4299.7280\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4133.5586 - val_loss: 4293.3706\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4125.7754 - val_loss: 4285.2783\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4118.1001 - val_loss: 4277.9458\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4110.9160 - val_loss: 4270.5957\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4102.3911 - val_loss: 4261.9883\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4094.6318 - val_loss: 4254.2222\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4086.7878 - val_loss: 4246.4087\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4079.4829 - val_loss: 4239.4868\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4072.5447 - val_loss: 4233.5547\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4064.8567 - val_loss: 4224.7065\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4056.1343 - val_loss: 4216.3354\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4049.1628 - val_loss: 4209.5396\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4042.5371 - val_loss: 4202.7852\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4036.0195 - val_loss: 4197.8735\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4031.3452 - val_loss: 4193.2466\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 4025.2578 - val_loss: 4187.4546\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4019.4788 - val_loss: 4182.5771\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4012.7783 - val_loss: 4174.1172\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4003.2446 - val_loss: 4164.8115\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3994.8020 - val_loss: 4158.8452\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3988.4663 - val_loss: 4150.9712\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3981.0056 - val_loss: 4143.7617\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3973.5950 - val_loss: 4137.8018\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3967.6318 - val_loss: 4132.0806\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3961.4888 - val_loss: 4127.0771\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3956.1072 - val_loss: 4122.1650\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3950.3599 - val_loss: 4116.2197\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3944.4609 - val_loss: 4110.5171\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3939.5598 - val_loss: 4105.3882\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3934.3108 - val_loss: 4100.2573\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3928.8152 - val_loss: 4094.9666\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3923.5835 - val_loss: 4090.7058\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3918.5779 - val_loss: 4086.0776\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3912.9133 - val_loss: 4080.0691\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3907.1814 - val_loss: 4074.6570\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3899.9802 - val_loss: 4066.6067\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3892.2754 - val_loss: 4059.0754\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3885.6204 - val_loss: 4054.0740\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3880.5305 - val_loss: 4048.8013\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3874.9153 - val_loss: 4043.5232\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3869.5120 - val_loss: 4038.5823\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3863.6477 - val_loss: 4031.9375\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3856.5676 - val_loss: 4025.1770\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3851.0457 - val_loss: 4020.9277\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3846.0691 - val_loss: 4016.6401\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3841.2993 - val_loss: 4011.3748\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3835.7649 - val_loss: 4005.3845\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3830.3523 - val_loss: 3999.8560\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3823.4426 - val_loss: 3992.5400\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3817.5549 - val_loss: 3987.5737\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3812.3914 - val_loss: 3984.2434\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3807.8176 - val_loss: 3979.8196\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3803.2175 - val_loss: 3975.5745\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3798.9153 - val_loss: 3971.1426\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3793.9136 - val_loss: 3965.8572\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3789.0493 - val_loss: 3960.6658\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3784.6680 - val_loss: 3956.8040\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3780.7908 - val_loss: 3953.3845\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3776.2585 - val_loss: 3948.5344\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3771.7500 - val_loss: 3944.2373\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3766.2004 - val_loss: 3938.5090\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3760.8765 - val_loss: 3933.9888\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3756.1516 - val_loss: 3930.1023\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3751.6111 - val_loss: 3926.1240\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3747.3301 - val_loss: 3922.1521\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3743.1880 - val_loss: 3918.1018\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3738.8938 - val_loss: 3913.3267\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3734.6240 - val_loss: 3909.9641\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3730.9443 - val_loss: 3907.0029\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3725.3757 - val_loss: 3899.9382\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3719.8909 - val_loss: 3894.4333\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3714.1636 - val_loss: 3887.7559\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3708.4661 - val_loss: 3883.0596\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3703.4016 - val_loss: 3876.8027\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3698.0188 - val_loss: 3873.2100\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3693.3430 - val_loss: 3867.7915\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3688.3586 - val_loss: 3862.5347\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3683.2065 - val_loss: 3857.3635\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3678.8083 - val_loss: 3852.5720\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3674.6179 - val_loss: 3847.8005\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3668.8457 - val_loss: 3841.2739\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3662.8452 - val_loss: 3837.1321\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3658.5061 - val_loss: 3834.0752\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3655.4395 - val_loss: 3830.2810\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3652.1282 - val_loss: 3826.7158\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3648.1091 - val_loss: 3823.3892\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3645.0576 - val_loss: 3820.2935\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3641.4167 - val_loss: 3816.8606\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3638.5195 - val_loss: 3815.4172\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3635.8572 - val_loss: 3813.4417\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3632.7258 - val_loss: 3810.9248\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3629.8726 - val_loss: 3807.8784\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3625.8750 - val_loss: 3803.1812\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3622.2852 - val_loss: 3799.4592\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3618.9482 - val_loss: 3796.4734\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3615.6143 - val_loss: 3793.6777\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3611.6448 - val_loss: 3789.5273\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3606.4341 - val_loss: 3784.2202\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3601.2744 - val_loss: 3780.1509\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3597.3579 - val_loss: 3776.2275\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3594.2161 - val_loss: 3773.0481\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3591.0457 - val_loss: 3768.5547\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3587.1621 - val_loss: 3765.6169\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3584.4358 - val_loss: 3762.3174\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3581.2068 - val_loss: 3758.4109\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3577.8303 - val_loss: 3756.3804\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3575.4714 - val_loss: 3754.2959\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3572.5959 - val_loss: 3753.0715\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3570.6282 - val_loss: 3751.0259\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3567.9326 - val_loss: 3748.8582\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3564.8945 - val_loss: 3747.0400\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3562.3457 - val_loss: 3744.0984\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3558.5613 - val_loss: 3741.4590\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3555.8333 - val_loss: 3737.6580\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3550.8113 - val_loss: 3733.8630\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3546.8970 - val_loss: 3729.8096\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3541.8984 - val_loss: 3724.6348\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3537.1040 - val_loss: 3722.4685\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3534.5564 - val_loss: 3721.2117\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3532.1062 - val_loss: 3718.5737\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3529.9675 - val_loss: 3714.9653\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3526.4709 - val_loss: 3712.3757\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3524.0234 - val_loss: 3709.6353\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3521.5417 - val_loss: 3707.3743\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3518.8813 - val_loss: 3705.4053\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3516.6343 - val_loss: 3703.0112\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3513.9321 - val_loss: 3699.9456\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3510.2458 - val_loss: 3696.5266\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3507.2712 - val_loss: 3693.9404\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3503.7227 - val_loss: 3689.9441\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3499.5457 - val_loss: 3687.3743\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3497.5259 - val_loss: 3685.3533\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3495.1423 - val_loss: 3683.1047\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3492.3923 - val_loss: 3680.2803\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3490.0291 - val_loss: 3676.7996\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3487.0598 - val_loss: 3673.6909\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3484.5312 - val_loss: 3671.6548\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3482.2588 - val_loss: 3670.1707\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3480.2839 - val_loss: 3668.2910\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3477.6243 - val_loss: 3665.5427\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3474.4915 - val_loss: 3662.8154\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3472.2356 - val_loss: 3660.2671\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3469.7373 - val_loss: 3657.9744\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3468.0100 - val_loss: 3656.0208\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3465.0254 - val_loss: 3654.5449\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3463.0708 - val_loss: 3652.4119\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3460.6343 - val_loss: 3650.9734\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3458.7568 - val_loss: 3649.5291\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3456.6831 - val_loss: 3647.7549\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3453.7793 - val_loss: 3645.4478\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3451.3142 - val_loss: 3643.7017\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3449.2000 - val_loss: 3641.5154\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3446.5007 - val_loss: 3638.8259\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3444.0156 - val_loss: 3636.9263\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3442.0894 - val_loss: 3634.5879\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3439.6833 - val_loss: 3632.5054\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3437.6067 - val_loss: 3630.8262\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3436.1980 - val_loss: 3629.8279\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3433.7344 - val_loss: 3627.8921\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3431.5435 - val_loss: 3624.5208\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3428.8657 - val_loss: 3621.7788\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3426.4890 - val_loss: 3620.0920\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3424.3877 - val_loss: 3618.7805\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3422.8103 - val_loss: 3618.4094\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3421.2595 - val_loss: 3617.0081\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3419.7075 - val_loss: 3616.1299\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3417.6243 - val_loss: 3614.3784\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3416.0266 - val_loss: 3613.4653\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3413.9277 - val_loss: 3611.9993\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3411.7910 - val_loss: 3610.7163\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3409.4180 - val_loss: 3608.6362\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3406.9561 - val_loss: 3606.6370\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3404.3892 - val_loss: 3604.9622\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3402.1523 - val_loss: 3603.4854\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3400.1052 - val_loss: 3602.2092\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3398.4417 - val_loss: 3600.5635\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3396.4714 - val_loss: 3598.4797\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3393.5525 - val_loss: 3596.6594\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3391.4685 - val_loss: 3595.4946\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3389.1213 - val_loss: 3593.7258\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3386.4617 - val_loss: 3591.5571\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3384.5107 - val_loss: 3589.7141\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3382.5054 - val_loss: 3588.5266\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3379.7329 - val_loss: 3586.3125\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3377.7883 - val_loss: 3584.4407\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3375.6660 - val_loss: 3582.0120\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3373.1636 - val_loss: 3580.4734\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3371.2305 - val_loss: 3579.1990\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3369.4727 - val_loss: 3577.9915\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3367.8665 - val_loss: 3576.3933\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3365.7649 - val_loss: 3575.3743\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3364.1575 - val_loss: 3574.7485\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3362.5583 - val_loss: 3573.1448\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3360.5803 - val_loss: 3571.4976\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3358.5505 - val_loss: 3568.8784\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3356.3552 - val_loss: 3567.8721\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3354.4377 - val_loss: 3566.1064\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3352.6873 - val_loss: 3563.4270\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3350.2461 - val_loss: 3561.2410\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3348.0591 - val_loss: 3559.7043\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3346.6321 - val_loss: 3558.4177\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3345.0337 - val_loss: 3557.4424\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3343.1853 - val_loss: 3556.1489\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3341.0818 - val_loss: 3554.7908\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3339.0566 - val_loss: 3553.0171\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3337.1821 - val_loss: 3551.0632\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3335.2776 - val_loss: 3549.3630\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3333.3572 - val_loss: 3548.4441\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3331.5291 - val_loss: 3547.9126\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3330.7249 - val_loss: 3547.1707\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3328.6328 - val_loss: 3545.4834\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3326.7942 - val_loss: 3543.8003\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3324.7312 - val_loss: 3541.0273\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3322.6731 - val_loss: 3539.3623\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3320.7971 - val_loss: 3538.1643\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3318.8469 - val_loss: 3536.7117\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3317.1360 - val_loss: 3535.3901\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3315.4773 - val_loss: 3534.2258\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3313.0061 - val_loss: 3531.8452\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3311.2852 - val_loss: 3530.4297\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3309.6975 - val_loss: 3529.2610\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3308.0520 - val_loss: 3527.9297\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3306.3083 - val_loss: 3526.7539\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3304.2288 - val_loss: 3524.7073\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3302.1614 - val_loss: 3522.3718\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3299.3992 - val_loss: 3521.3115\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3297.3000 - val_loss: 3520.2131\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3295.4277 - val_loss: 3519.2219\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3293.7493 - val_loss: 3518.1416\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3291.5100 - val_loss: 3516.6826\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3289.8428 - val_loss: 3515.4233\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3288.4065 - val_loss: 3514.1409\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3287.2627 - val_loss: 3512.8198\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3285.5266 - val_loss: 3511.7917\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3283.9292 - val_loss: 3510.7903\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3282.1716 - val_loss: 3509.8132\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3279.9526 - val_loss: 3508.5425\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3278.3760 - val_loss: 3507.1970\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3276.6357 - val_loss: 3506.5435\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3274.5093 - val_loss: 3504.8472\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3272.9529 - val_loss: 3503.4785\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3271.6455 - val_loss: 3502.4873\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3269.1477 - val_loss: 3502.4185\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3267.7188 - val_loss: 3501.4221\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3266.1628 - val_loss: 3501.3325\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3264.8638 - val_loss: 3500.1804\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3263.6689 - val_loss: 3499.1741\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3263.2971 - val_loss: 3499.6812\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3262.2178 - val_loss: 3499.0247\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3260.9495 - val_loss: 3498.1426\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3259.5242 - val_loss: 3497.8635\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3257.4714 - val_loss: 3497.2156\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3256.3081 - val_loss: 3496.1609\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3254.5471 - val_loss: 3494.2036\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3253.0808 - val_loss: 3493.3943\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3251.8064 - val_loss: 3493.0278\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3250.5583 - val_loss: 3492.2935\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3249.4207 - val_loss: 3491.8772\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3247.4270 - val_loss: 3490.0208\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3246.1736 - val_loss: 3488.8154\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3244.3999 - val_loss: 3487.8435\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3243.2412 - val_loss: 3486.8831\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3241.8987 - val_loss: 3485.6328\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3240.1218 - val_loss: 3484.7451\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3238.1936 - val_loss: 3483.9172\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3236.2786 - val_loss: 3483.8115\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3235.1394 - val_loss: 3482.8943\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3234.0339 - val_loss: 3482.4290\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3233.1130 - val_loss: 3482.6033\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3231.8953 - val_loss: 3482.6812\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3231.1179 - val_loss: 3482.8030\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3229.7454 - val_loss: 3482.1328\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3227.9692 - val_loss: 3481.5615\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3226.6897 - val_loss: 3480.9004\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3225.2539 - val_loss: 3479.9785\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3224.1023 - val_loss: 3479.7158\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3223.1038 - val_loss: 3478.7566\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3221.5320 - val_loss: 3476.5310\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3220.1179 - val_loss: 3475.2236\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3219.0149 - val_loss: 3474.0054\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3217.1323 - val_loss: 3472.3030\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3215.5015 - val_loss: 3471.2141\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3213.4907 - val_loss: 3469.5647\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3211.0037 - val_loss: 3467.8809\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3209.8679 - val_loss: 3467.1733\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3209.3123 - val_loss: 3466.2458\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3207.5942 - val_loss: 3465.3379\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3206.2266 - val_loss: 3464.5225\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3205.2170 - val_loss: 3463.5740\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3203.7744 - val_loss: 3462.1011\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3201.8052 - val_loss: 3460.4817\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3201.1526 - val_loss: 3460.3284\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3200.4568 - val_loss: 3459.6267\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3199.3877 - val_loss: 3458.7708\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3198.2358 - val_loss: 3457.3679\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3197.0808 - val_loss: 3455.9336\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3195.0266 - val_loss: 3454.1274\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3193.1802 - val_loss: 3453.1531\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3192.2546 - val_loss: 3452.1953\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3190.9370 - val_loss: 3451.9177\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3189.7383 - val_loss: 3451.2759\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3188.7078 - val_loss: 3450.9404\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3187.9385 - val_loss: 3450.6765\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3187.7312 - val_loss: 3450.0554\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3186.5581 - val_loss: 3449.4773\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3185.5356 - val_loss: 3448.2556\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3184.6570 - val_loss: 3447.9922\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3183.7793 - val_loss: 3447.1331\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3182.8325 - val_loss: 3446.3835\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3182.1870 - val_loss: 3445.5427\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3180.6465 - val_loss: 3444.8638\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3179.6526 - val_loss: 3444.2534\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3178.2908 - val_loss: 3443.6377\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3177.3914 - val_loss: 3443.2651\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3176.2734 - val_loss: 3442.7129\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3175.2712 - val_loss: 3442.0842\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3174.1685 - val_loss: 3441.3215\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 3173.1013 - val_loss: 3440.6467\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3171.8940 - val_loss: 3439.8469\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3171.0361 - val_loss: 3439.6396\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_transformed, Y_train, epochs = 1000,\n",
        "                    batch_size = 32,validation_data=(X_test_transformed, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhWlxfi9GQWV"
      },
      "source": [
        "### Plot train and test loss as a function of epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LYSUu_SwGQ-z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "3a395514-2ddf-4e14-9e8a-ae98a8646b29"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAFeCAYAAAB9+JNtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfmElEQVR4nO3dd3wUdfrA8U8CJEhIQgkk1CA1lFClRIEgHIinCIqCPXgeInAqivW8+1E8BAQVpUo5UESQoxepAiIQWkR6KJpQQgqkJ2wqz++PyS4sCZBN25Tn/Xo9r+zOfHf2md2ZPDsz35lxAASllFLKBo72TkAppVTJo8VDKaWUzbR4KKWUspkWD6WUUjbT4qGUUspmWjyUUkrZTIuHUkopm2nxUEopZTMtHkoppWymxUMVGzt37kSkYC54UL58ecaMGcPZs2dJSUlBROjfv3+BTFuVLWPGjEFE8Pf3t3cqxYrdi4e3tzciwqZNm+ydSqkgIveMsmD06NGMHTuWK1euMHXqVMaOHUtwcLC90yoVzOvswoUL7Z1KgSjq+fHy8mL+/PlcuXIFk8lEcHAw//znPylfvrzN03r++ec5cOAASUlJxMTEsH79etq1a5dj2xdeeIE5c+Zw6NAhyw+qgICAPM+H7dmqYu/atWvMmDHD3mnY1eOPP05iYiK9e/cmPT3d3ukoBYCnpycHDhygbt26rF69mnPnzuHv78+ECRPo1KkTAwYMyPW0/vnPfzJhwgRCQ0OZM2cOrq6uPPvss+zbt49evXqxb98+q/b/+c9/aNCgAVevXiU8PJwGDRrke37EnuHt7S0iIps2bbJrHqUlREROnz5t9zzyEjt37hQxNo3yHX/88YeEhITYfZ5KY5jX2YULF9o9l6KYnzFjxoiIiL+/f77fa9GiRSIiMmzYMKvhP/zwg4iIPPvss7maTuPGjSUtLU2Cg4PFzc3NMrxNmzZiMpnk5MmT4uDgYPWaXr16Sf369QWQDz74QEREAgIC8jM/xeOLy23xqF+/vsyfP18uX74sqampcunSJZk/f77Uq1cvW1svLy+ZNm2anD17Vq5fvy6xsbFy6tQpmT17ttUH7ubmJuPGjZOTJ09KYmKixMfHy7lz52TRokWWD/tO0bVrVxERWbBgQY7ja9SoIWlpabJnzx6b88pL2Fo8QkJCJCQkRNzd3WXOnDkSHh4uJpNJfvvttzsuyJUqVZKxY8fK6dOnxWQySXR0tGzYsEEefPDBO77PkCFDZPfu3RIbGyvJycly9uxZmTNnjtX3Zi4e5cuXlzFjxkhISIikpKTImTNnZPjw4bmaH/OKfrvbC8mQIUNk//79kpiYKImJibJ///4cVyR/f38RERkzZoz4+fnJli1bJDY2NldF7tbPdvr06XLx4kVJT0+3eh9fX19ZunSpXLlyRVJTUyU0NFS+/vprqVatWo7TfO211+TEiRNiMpnk4sWLMnnyZHF2dhYRkZ07d+Z7fXzqqadk165dEhkZKSaTScLCwmTbtm3y1FNPCSABAQE5fr63/nO99Z9tQECABAUFSXJyslV+lStXlrFjx8qJEycs68DmzZvloYceypZTXpaL6tWryzfffCORkZGSnJwsBw8elAEDBljyN38Hts7Pc889J0eOHJHr16/LlStXZNq0aVKxYsVcfbaVK1cWk8kk58+fzzaufv36IiLy888/52paEyZMEBGRl156Kdu4//73vyIi0q1btzu+viCKR4nabdWkSRP27NlDzZo1WbduHSdPnqRVq1a8+uqr9OvXj65du3Lu3DkA7rvvPvbu3UuDBg3YunUrq1evxsnJifvvv5+XXnqJqVOnkpCQAMCWLVvo0qULe/bsYfPmzdy4cQNvb2+eeOIJFi9ezMWLF++Y0549ewgJCWHgwIGMGDGC1NRUq/HPPfccFSpUYPHixTbnVVScnJzYvn07lStXZvHixbi4uDBo0CCWLl2Kh4eH1S4wZ2dnduzYQefOnQkKCmLatGl4enoyePBgHnnkEZ577jlWrFhhae/g4MCPP/7IM888w+XLl1m6dCkJCQk0aNCAQYMGsWnTJi5dumSVz9KlS+nUqRObNm0iMzOTQYMGMWvWLNLT05k/f/5d52XXrl2MHTuWUaNGATBt2jQA4uLiLG2++uor3nzzTS5fvsyCBQsAGDhwIIsWLaJdu3aW197qwQcf5J///Cc7d+5k7ty51K9fP1efrfnzqly5MuvWrSMjI4PIyEgA+vXrx/Lly7lx4wZr167l0qVLtGjRgjfeeINHHnmEzp07W+U9btw4/u///o+IiAjmzZtHeno6gwYNwsfHJ1e53Mvrr7/O7NmzuXLlCqtXryY6OhovLy86derEk08+yapVq/j999+ZNm0ao0aN4vfff2fNmjWW14eGhlpN77333uPhhx9m7dq1bN26lczMTACqVq3K7t27adWqFXv27GHOnDm4ubnRv39/du7cyTPPPMPatWuz5Zfb5cLFxYVffvmFli1bsnfvXnbv3k3dunVZtmwZW7ZssZqmLfPzj3/8g759+7J27Vp27NhB3759eeutt/Dw8ODFF1+85+fr5+dHxYoV2bZtW7ZxFy9eJDg4mIceeghHR0du3Lhx12n16NEDgK1bt2Ybt2XLFl555RX8/f359ddf75lXfuT710p+wpYtj59//llERIYOHWo1fPjw4SIisn37dsuwxx9/XEREvvjii2zTcXFxEScnJwGkVatWIiKyatWqbO2cnJzExcXlnnmNHz9eRESeeeaZbOMOHTokKSkpUrVqVZvyymuIiFy9elXGjBmTYwwePNiqfUhIiIiI7Nq1SypUqGAZXqdOHYmKihKTySS1a9e2DP/3v/8tIiKLFy+2mk7btm0lJSVFYmJipHLlypbhI0eOFBGRbdu2ZfuFVrFiRcvnAjd/YQYGBoqrq6tleNOmTSUtLS1PW1S3D+/WrZuIiJw8edJqK69KlSoSHBwsIiJdu3a1DDdveYiIDBkyxKbvwvzZbtq0Kdu8V6tWTeLi4uTSpUvZtm4HDx4sIiJff/21ZViTJk0kPT1dLl26JDVq1LAMr1y5spw4cUJE8r/lcfjwYUlJSbGa/q35mh/ndjdPYmKitGrVKtv477//XkREXn31VavhNWrUkAsXLkhkZKQ4Ozvnebkwr49z5syxGt6zZ0/Ld3nrL+7czk9sbKw0bdrUavkNDg6WjIwMqVWr1j0/3xEjRoiIyDvvvJPj+HXr1omIyP3333/PaUVFRUlCQkKO49q3by8iIt9+++0dX1+mdlvVq1dPREROnDiRbZyDg4OcOnVKRETq1q0rcPOf9IQJE+46XXPxWLJkSZ7noUmTJiIisnbtWqvhPj4+2QpTbvPKa9zL6tWrrdqb/8HltMvp448/zrawnz9/XlJTU6VOnTrZ2n/zzTciIvLiiy9ahp08eVLS09OlcePG98zd/E+iR48edxx3a2G6W9ypeMyfP19Eci70zz33nIiIzJ8/3zLMXDwOHz5s83dh/mx9fX2zjRs1alS2z+rWOHz4sERFRVme/9///Z+IiIwaNSpb22effVZECqZ4JCYmSpUqVe7aLrf/bD///PNs46pXry7p6elWP/RujX/84x8iIvLYY4/lebn4888/JSUlRWrWrJmt/ebNm7P908zt/IwdO/aO4x5//PF7fr4fffSRiGQvmuYwF9W2bdvec1rmXfY5jWvcuLGIiKxZs+aOry9Tu63atm0LwC+//JJtnIiwe/dumjdvTtu2bbl8+TK7d+/mypUrfPjhh7Rp04YNGzbwyy+/cPr0aavXnj59mqNHj/L8889Tt25d1qxZw65du/j9999z3a313LlzHDhwgL59+1K9enWio6MBLJuy5l1WQK7zyo/g4GCaN2+e6/bp6ekEBgZmG27e5DV3/XN1daVRo0acOnWKsLCwbO137tzJa6+9Rtu2bfn+++9xcXGhRYsWnDt3jvPnz+c6n6CgoGzDLl++DECVKlVISkrK9bRuZ56XXbt2ZRu3c+dO4OaydqtDhw7l6f1MJhPHjx/PNrxLly4AdO7cmUaNGmUbX7FiRWrUqGFZntq0aQMYu0lvt3fv3jzldrtly5YxZcoUTpw4wQ8//MDOnTvZs2cPiYmJeZrewYMHsw3r2LEj5cuXx9nZmTFjxmQb36RJEwB8fHzYuHGj1bjcLBeurq7cf//9nDx5kqioqGzt9+7dyyOPPJKn+bnX+5c1JaZ4uLm5AVj2F98uPDzcql1CQgJdunRh/Pjx9OvXj8ceewww9i1OmjSJ2bNnA5CZmUnPnj0ZO3YsAwcO5IsvvgAgKiqKGTNmMGHChHvufwSjQHTu3JnBgwcza9YswOhXHRMTY7US5DavonTt2rUcC6X5s3Z3dwds/w7Mr8up0NxNTv+sMjIyAChXrpxN07qdm5sbmZmZXL16Ndu4yMhIbty4Ycn/9nF5kdM/MIBq1aoBxn70u3FxcSE6OtqSU07Ty2tut5s6dSrR0dEMHz6c0aNH895775Gens7GjRt5++23sx0DuJec8jLPd9euXenatesdX+vi4pJtWG6Wi7t9TnfKKbdyOhZpy3IZHx8P3FwvbmfO3dzuXtMqiOnkh91PEswt8xfn6emZ43gvLy+rdgCXLl3ilVdeoUaNGrRt25b3338fR0dHZs2axbPPPmtpFxMTw5tvvkmdOnVo3rw5I0eOJCYmhvHjx/P+++/nKr9ly5aRlpZm2dro3r07DRo0YPny5aSlpVm1zW1eRcXDwwMHB4dsw82ftXkhtPU7ML+uTp06BZtwPiQkJFCuXDlq1KiRbVzNmjVxdHTM8Z9EbrdCc/s683u0atUKBweHO4a5s4a5fc2aNbNN607fR14sXLiQTp06UaNGDQYMGMCqVasYMGAAGzZswNHRtn8XOc27eT6mTp161/keP358nvK/2+cEBftZ2crcmce8dXW7Jk2akJqaetcOOrdOy9XVNcf5MU/f/H6FpcQUj99//x0w/innxDzc3O5WIsLRo0eZMmUKzz33HABPPPFEjtMJDg5m1qxZ9O7d+67tbhcdHc3mzZvx8/OjUaNGliLy/fff3/E1tuRVmCpUqICfn1+24d26dQPgyJEjgPHL748//qBx48bUrl07W3tzDxDzd5CcnMzJkye5//77ady4ceEkbyPzvJhzvdXt+RemAwcOAOT4uefk6NGjADz00EPZxj344IMFl1iWmJgY1q5dy7PPPsvPP/9My5YtLd+huddUXrYCDx06xI0bN3I937ZKTEwkJCSExo0b5/gDIafPKj/zY4v9+/eTmppq+d9yq/r16+Pj48PevXst+dyNefd9nz59so0z75bLaRd/QSoxxePSpUvs2LGDVq1a8be//c1q3GuvvUaLFi34+eefLfsgW7RocddfaSkpKYBxaQJvb+97tssN87GNv//97zzzzDP8+eef2fZH5zYvMLr1NmvWjHr16uU6h7z69NNPqVChguV5nTp1eOutt0hJSWHZsmWW4d9++y1OTk5MnDjR6vW+vr4MGTKEuLg4q+6OM2fOpHz58syaNYuKFStavcbZ2ZmqVasWzgzdwbfffgsY1ytydXW1DHdzc7Psgze3KUwLFy4kISGBCRMm0KJFi2zj77vvPjp37mx5vmzZMjIzMxk9ejTVq1e3DK9UqRIff/xxju/h5uZGs2bNLFuE95LTtZvKly9v2dVkXjZjY2O5ceNGnpbLyMhIli9fzkMPPcS7776bY5tOnTpx33332TxtsyVLluDs7My4ceOshvv7+9O3b99s7fMzP7ZITExk2bJlNGrUiGHDhlmNM69P8+bNsxp+p+9w4cKFpKen8/HHH1vtZm3Tpg3PPfccp06dyvH4WEEqNsc8fH1973htmeDgYCZPnszw4cPZs2cP8+bNo1+/fpw6dYqWLVvSv39/oqKiGD58uOU1vXv3ZsqUKezdu5ezZ88SHR1Nw4YNeeKJJzCZTMycORMwDo6uWrWKgwcPcurUKSIiIqhTpw4DBgwgMzOTL7/8MtfzsH79euLi4njnnXdwcnLi66+/ztYmt3mBsRLt2rWLXbt28fDDD+c6Dw8PjxwPRprNmTPHat/vlStXcHFx4dixY6xfv95ynoeHhwdvvPEGV65csbT97LPPeOyxx3j55Zdp3rw5P//8MzVr1mTw4MGUL1+eoUOHWh3Qnj17Nv7+/gwePJhz586xbt06EhISqF+/Po888givvvpqjn36C8uvv/7K119/zZtvvsmJEydYuXIlDg4ODBw4kHr16vHVV18Vet94MI4zPffcc/zvf//j6NGjbN68meDgYJydnWnQoAH+/v7s27ePRx99FICzZ88yadIkPv74Y44fP87y5cvJyMjgqaee4vjx4/j6+mY7Nvfkk0+yaNEiFi1axCuvvHLPnNasWUNCQgL79+/nwoULVKhQgd69e9OyZUv+97//WXanJCcnc+jQIbp37853333HuXPnuHHjxj3PiTIbMWIEzZo1Y8qUKbz00ksEBgYSFxdHvXr1eOCBB2jatCleXl6YTKY8fLIwefJkBg4cyPDhw2nVqhW//vordevWZdCgQaxbt44nnnjC6rPK7/zY4sMPP+Thhx9m1qxZ/OUvf+H8+fP4+/vj5+fHunXrrH6owZ2/w3PnzjF27FgmTJjA0aNHWblypeXyJABDhw7Nttvw1VdftRxn8vX1BYwfuuYt7j179ljOe8qtfHXvy2+Yu8ndza1dEOvXry8LFiyQsLAwSUtLk7CwMFmwYEG2vvI+Pj7y5ZdfSlBQkFy9etVyZufChQulefPmlnZ16tSRTz/9VPbt2ycRERGSkpIioaGhsmLFCuncubPN8zN37lxL3k2aNMk2Prd5wc1uorZ0wcyNNm3aWNqbu7RWqVLF6gzzI0eO3PUM83HjxklwcLDl3I6NGzfmeHawOf72t7/Jvn37JDExUZKSkuTMmTMya9YsS9dquPvlSRYuXCgiIt7e3rn6HO7UVdccQ4YMkQMHDkhSUpIkJSXJgQMHcjyP49YzzG1dFu6VAxjnKsybN89y1nR0dLQcPXpUpk2bJg888EC29q+//rqcPHlSUlJS5OLFi/LZZ59JnTp1RCR7N2zz2dO5vYzI66+/LmvWrJGQkBC5fv26XL16Vfbv3y/Dhg2T8uXLW7Vt0qSJbNiwQWJiYiQzM1NEcj4j+07vVbFiRXn33Xfl0KFDkpiYKMnJyfLHH3/IqlWr5MUXX5Ry5crla7nw8PCQefPmSVRUlFy/fl0OHTokAwYMkHfeeUdERPr3718g83P7Geu5CS8vL5k/f76Eh4dbzpT/+OOPrc6zyu13+Pzzz8vBgwclOTlZYmNjZcOGDdKuXbu7flZ3kofLzdi2QmiUrsjNPziN4h29evUSEZFJkybZPZfiHosXLxYRER8fH7vnUgrC7glo2DG0eJSc8PDwEEdHR6th7u7ucvDgQRER6dKli91zLC7h5eWVbVj37t0lPT29xF44tLhFsTnmoZS6uxdeeIF3332XHTt2cOXKFWrVqkXfvn3x9PRk4cKF7N+/394pFhs//fQTJpOJ33//neTkZFq0aEHfvn3JzMzkjTfesHd6pYbdK5iG/UK3PEpOdOzYUdasWSNhYWFiMpkkKSlJDh06JCNHjsx2+e2yHm+99ZYcPHhQoqOjJS0tTaKiomT16tXSqVMnu+dWWsIh64FSSimVayXmPA+llFLFhxYPpZRSNtMD5oWodu3aeb4iqVKqeHJ1dbU6cbas0uJRSGrXrm3z1WSVUiVDnTp1ynwB0eJRSMxbHHXq1NGtD6VKCVdXV8LCwnSdRotHoUtMTNQFTSlV6ugBc6WUUjbT4qGUUspmxap4vP766xw9epT4+Hji4+PZt2+f1fX3nZ2dmTFjBteuXSMxMZEVK1ZkuzdGvXr12LBhA8nJyURGRvLZZ59lu8mLv78/QUFBpKSkcO7cOQICArLlMmLECEJCQjCZTOzfv5+OHTsWzkwrpVQJVKyOeVy+fJkPP/yQc+fO4eDgQEBAAGvXrqVdu3acOnWKL7/8kscee4xnnnmG+Ph4ZsyYwapVqyzXqHd0dGTjxo1ERETw4IMPUqtWLb777jvLTVMAGjRowMaNG5kzZw4vvPACvXr1Yv78+YSHh7N161YABg0axBdffMHrr7/OgQMHGDVqFFu2bKFZs2Y53vtaqeKkUqVKd7y1sLq7GzduEB4ebrk3ubqzYn95kujoaN577z1WrFjB1atXef7551m5ciUAzZo1Izg4mC5dunDgwAH69u3Lhg0bqF27NlFRUQAMGzaMyZMnU6NGDdLT05k0aRKPPfaY5WYoAEuXLqVKlSqWG+/s37+fQ4cOWS6g5uDgwKVLl5g+fTqTJ0/OVd6urq4kJCTg5uamB8xVkXBwcOCVV17J8Ra7KvdSUlL4+OOPc/yhqOv1TcVqy+NWjo6OPPPMM7i4uBAYGEiHDh1wcnJi+/btljZnzpzhwoUL+Pn5ceDAAfz8/Dh+/LilcABs2bKFOXPm0LJlS37//Xf8/PyspmFuM23aNMC4n3eHDh2sbrMqImzfvv2u9112cnLC2dnZ8vzWW5wqVRReeeUV/P39+fHHHwkODtZfz3ng7OzM66+/ztChQ5k4cWK2u/Gpm4pd8WjVqhWBgYFUrFiRpKQknnzySU6fPk3btm1JTU0lPj7eqn1kZKTl/r5eXl5Wt1c1jzePu1sbd3d3KlasSNWqVSlfvnyObXx8fO6Y90cffcTYsWPzNM9K5ZeLiws9evTgxx9/ZOPGjfZOp0Rbvnw5I0aMwN3dnbi4OHunU2wVqwPmYGxNtG3bls6dOzN79my+/fZbmjdvbu+07mnixIm4ublZok6dOja82gdoX1ipqTKgevXqAAQHB9s5k5LPvOfCzc3NzpkUb8VuyyM9PZ0//vgDgN9++42OHTvy1ltv8eOPP+Ls7Iy7u7vV1oenpycREREARERE0KlTJ6vpeXp6WsaZ/5qH3domPj6elJQUrl27RkZGRo5tzNPISVpaGmlpaXmc64+BF4EjwHzgByAuj9NSZZH54Ljuqsq/zMxMAO1wcA/Fbsvjdo6Ojjg7OxMUFERaWhq9evWyjGvatCne3t4EBgYCEBgYiK+vLzVq1LC06d27N/Hx8Zw6dcrS5tZpmNuYp5Genk5QUJBVGwcHB3r16mVpU/BSs6IdMBO4AnwHdC+k91NKqfyz+x2pzPHpp59Kt27dxNvbW1q1aiWffvqpZGZmyl/+8hcBZNasWRIaGio9evSQ9u3by969e2Xv3r2W1zs6OsqxY8dk8+bN0rp1a+nTp49ERkbKhAkTLG0aNGggSUlJMnnyZGnWrJkMHz5c0tPTpU+fPpY2gwYNEpPJJC+//LL4+PjInDlzJCYmRmrWrJnreXF1dRUREVdX11y+pprAGwLHBOSWOCPwvoCn3b8fjeIb3t7e8t1334m3t7fdc7F3hISEyFtvvVUon6Xt63WpDrsnYIn58+dLSEiIpKSkSGRkpGzbts1SOABxdnaWGTNmSHR0tCQlJcnKlSvF09P6n2r9+vVl48aNkpycLFFRUTJlyhQpV66cVRt/f3/57bffJCUlRc6fPy8BAQHZchk5cqSEhoZKSkqK7N+/3+bbV+ZvIeso8I1AgmApImkCKwUeFXC0+3elUbyiJBaPexkzZkyepuvh4SH33XdfoXyWWjyswu4JlMoomIXMReAVgb2C1dbIeYEhAuXtPp8axSNKYvHw9PS0xJtvvilxcXFWw1xcXKza3/4j0B6fpRaPm1Hsj3mUbcnAQuAhoBXwJRANNMoafgZ4hWLY70Gpe4qMjLREfHw8ImJ57uPjQ1JSEn379uXw4cOkpqbStWtXGjZsyJo1a4iIiCAxMZGDBw9mO4YZEhLCW2+9ZXkuIrz66qusWrWK5ORkzp49S79+/Yp6dksdLR4lxkngHaA+8C4QCTQE/otRRAbaLzVVTFWyUxScSZMm8eGHH9K8eXOOHTtG5cqV+emnn+jVqxft2rVj8+bNrF+/nnr16t11OmPGjGH58uW0bt2an376iSVLllC1atUCzbUssvvmT2mMwt+8rSTwjkCEYNmdtV2gud3nXaPoI/uulkqC1a7OooxKNucfEBAgsbGxluf+/v4iIvLEE0/c87XHjx+XkSNHWp7ffsBcRGT8+PGW55UqVRIRkUceeSSXn+XN0N1WN0O3PEqs68AXGFsf44AUoBfwO/ABulGpSoPDhw9bPXdxcWHKlCmcOnWK2NhYEhMTad68OfXr17/rdI4dO2Z5fP36deLj47NdkVvZRneWl3jXgbHAt8BXQD9gUtbfl4E/7ZaZsqfrgIsd37tgJCcnWz2fOnUqvXv35t133+X8+fOYTCZWrFiBk5PTXaeTnp5u9VxEcHTUH1j5ocWj1AgBngACgK8xDrIfBV4DltoxL2U/BfdPvLh46KGHWLRoEWvWrAGMLZEGDRrYNaeySktvqfMt4AvsBCpjXOrkX3bNSKmCcu7cOZ566inatGlD69at+eGHH3QLwk70Uy+VLmIc/5iU9fwTjF5ZFeyWkVIF4Z133iE2NpZ9+/axfv16tmzZwm+//WbvtMosux+1L41RfHplvCaQLlh6Y7nb/bPRKPgoiScJFtfQ3la5C93yKPXmYhw8T8TYGtkLeNs1I6VUyafFo0zYDHQFLgMtgf1AB7tmpJQq2bR4lBnHgC4YPbC8gB3AA3bNSClVcmnxKFPCgG4YPbHcgC0YPbOUUso2WjzKnESM80ECgWrAdqCZXTNSSpU8WjzKpCTgUeA3oCbGFkiNu75CKaVupcWjzIoH+gBnMXpfrQLufokHpZQy0+JRpkVjdOONw+iNNcOu2SilSg4tHmXeWWAQkAkMBZ6ybzpKqRJBi0cx8B7wE8Y9Ae1ze5pt3LyUyVygll2yUEqVHFo8ioEXMA5f/xfj/oA/AUOAKkWaxTggCKielYlShUtE7hpjxozJ17T79+9fgNmq22nxKAYGYVz39hjGpQsfxbhDeRSwEaOQuBd6FunAi4AJ6AuMLPR3VGWbl5eXJd566y3i4+Othk2dOtXeKaq70OJRDJwFJgBtAB/g39wsJH/FKCRXgEUYh7ULTzDGTjSAKVnZKFU4IiMjLREfH4+IWA179tlnOXXqFCaTidOnTzN8+HDLaytUqMD06dO5cuUKJpOJ0NBQPvzwQwBCQkIAWLNmDSJiea4Klt4Mqpg5A/wnK5oBzwDPYlyRKiArgoGZGEUlOefJ5MNM4HGMrY//YtxUSgr8XVThq2Sn9y2IW1A9//zzjB8/nn/84x8cOXKEdu3aMW/ePJKTk/nuu+948803eeKJJxg0aBAXL16kXr161KtXD4COHTty9epVhgwZwubNm8nMzCyAjNTttHgUY7cWks7A3zEKiQ8wHRgPzMHoYHulQN/5VeA04Jf1eH6BTl0VvkoUxg+L3HEh/wVk3LhxjB49mtWrVwMQGhpKixYtGDZsGN999x3169fn3Llz7NmzB4CLFy9aXnvt2jUA4uLiiIyMzGcm6k50t1UJcQCjI20tYATGrq6qwEcYdyn/HONQd8G4Avxf1uPJgEeBTVmpe6lUqRKNGzdmwYIFJCYmWuJf//oXjRo1AmDRokW0bduWM2fO8NVXX9G7d287Z1326JZHCZMEzMbY4ugHvItxqcN3MLZMpmaFKd/vNAPjUH1b4DPgb/meoio61zG2AOz13vlRuXJlAIYOHcqBAwesxpl3QR05coT777+fRx99lL/85S8sX76c7du388wzz+Tz3VVuafEooQRYlxW9gYkYd+gYj3G+yFvA+ny9QyYwHOMCiq9glKxD+ZqiKloFcezBHqKioggLC6Nhw4b88MMPd2yXmJjI8uXLWb58OStWrGDLli1UrVqV2NhY0tLSKFeuXBFmXfZo8SgFtmFcG/cZjD5S92MUlbXAaxhdfvNmP0YfryEYWx8P5ytPpXJrzJgxfP3118THx7N582acnZ154IEHqFq1Kl9++SVvv/024eHhHDlyhBs3bvDMM88QHh5OXFwcYBwj6dWrF3v37iU1NdUyXBUcPeZRSgiwHGgOfAqkAf0xuvw+kq8p/x+QAvTA6DisVOFbsGABf//733nllVc4fvw4v/zyC0OGDLF0u01MTOT999/n8OHDHDp0iAYNGvDXv/4VEaNn4OjRo+nduzeXLl3iyJEj9pyVUs3uN1IvjeHq6ioiIq6urnZ5/1YgR0EkK8YbN6zP4/QmZU3muICj3T9bjezh7e0t3333nXh7e9s9l5Ied/ss7b1eF6fQLY9S6gTQCeOsDTBOPMz7XTsmATFAK4wzTZRSZZ0Wj1IsFfgH8DxGn/+/AEcw7mRumziMc+DBOCR/X4Hkp5QqubR4lAFLgY4Yp/3VAXZg3IjWNjOBUKAu8GbBJaeUKpGKVfH48MMPOXjwIAkJCURGRrJ69WqaNm1q1Wbnzp3Zrr45e/Zsqzb16tVjw4YNJCcnExkZyWeffZat256/vz9BQUGkpKRw7tw5AgKy744ZMWIEISEhmEwm9u/fT8eOHQt+povIaYwCsg5ju2EVxrnjuZeKcflGME5NLLhTEpVSJU+xKh7+/v7MnDmTLl260Lt3bypUqMDWrVupVMn6Kj1z5861uvrm+++/bxnn6OjIxo0bcXJy4sEHHyQgIIAhQ4Ywfvx4S5sGDRqwceNGdu7cSdu2bZk2bRrz58+nT58+ljaDBg3iiy++YNy4cbRv356jR4+yZcsWatQouff6Tsa41dMCoBzGRUf+adMUfsDY8eWOUUBUcWHuZVS+vPa+zy/zD03zZ6ruzO5H7e8UHh4eIiLSrVs3y7CdO3fKl19+ecfX9O3bVzIyMqRmzZqWYcOGDZO4uDipUKGCADJp0iQ5fvy41euWLl0qmzZtsjzfv3+/TJ8+3fLcwcFBLl++LB988EGuci/uvTL+w82eWJ/Y9NpHsl6WLOBp9/nQMMLFxUW+++47eeyxx+yeS0mPLl26yHfffSdVqlTJNq64r9dFGcX6Z4q7uzsAMTExVsNfeOEFXnzxRSIiIli/fj2ffPIJJpNxQQ4/Pz+OHz9OVNTNU+O2bNnCnDlzaNmyJb///jt+fn5s377dappbtmxh2rRpgHG55w4dOjBx4kTLeBFh+/bt+Pn5FcasFrl/AVeBaVmPk7l5L8G724Jx1rkfxuXb3y2U/JRtkpOT2bVrF4MGDQIgODiYjIwMO2dV8jg7OzNo0CCCg4OJj4+3dzrFWrEtHg4ODkybNo09e/Zw8uRJy/AffviBCxcucOXKFVq3bs3kyZNp1qwZAwcOBIwbzNx+JU3zcy8vr7u2cXd3p2LFilStWpXy5cvn2MbHJ+d7XDg5OeHs7Gx57urqmsc5LzpfYdwzZArG5U2igXm5euU4YDPG5UumYNz/UNnbwoULARg8eLCdMynZUlJSmDhxou62uodiWzxmzpxJq1at6NrV+vZH8+bd/Pd24sQJwsPD2bFjBw0bNuTPP/8s6jQtPvroI8aOHWu398+rqYArxnnkszCu0PvzPV+1BePSJV0wtjzeu3tzVSREhP/+978sW7YMDw8PHBwc7J1SiZOZmUlERIRuteVCsSwe06dP5/HHH6d79+6EhYXdta35qpuNGzfmzz//JCIigk6dOlm18fT0BCAiIsLy1zzs1jbx8fGkpKRw7do1MjIycmxjnsbtJk6cyBdffGF57urqes/ci4sxGNfDeglYgVESztzzVeMx7rY+DOMckLhCy0/Z5vr161b3t1CqMBSr3lZgFI4nn3ySnj17Ehoaes/2bdu2BSA8PByAwMBAfH19rXpF9e7dm/j4eE6dOmVp06tXL6vp9O7dm8DAQADS09MJCgqyauPg4ECvXr0sbW6XlpZmde+BxMTEXM9zcfB34FegCkYBufdd6DYBxzG2W14vxMyUUsWV3Y/am2PmzJkSGxsr3bt3F09PT0tUrFhRAGnYsKH861//kvbt24u3t7f069dPzp8/L7t27bJMw9HRUY4dOyabN2+W1q1bS58+fSQyMlImTJhgadOgQQNJSkqSyZMnS7NmzWT48OGSnp4uffr0sbQZNGiQmEwmefnll8XHx0fmzJkjMTExVr247hYlsVeGJ8gVjB5Y/83Va14Uo3m4gLPd89fQKOwoiet1IYbdE7DEnQQEBAggdevWlV27dsm1a9fEZDLJ2bNnZfLkydm+yPr168vGjRslOTlZoqKiZMqUKVKuXDmrNv7+/vLbb79JSkqKnD9/3vIet8bIkSMlNDRUUlJSZP/+/dKpU6dSv5D5g2RgFJAX7tm+vECoGM2H2j13DY3CjpK6XhdS2D2BUhkleSH7N0bxSABpeM/2b4nR/LSAg91z19AozCjJ63VBR7E75qHsbwLwC8bRjB8wzka/swUYB8t9gMcKOTOlVHGhxUNlcwN4EaMkdAZG37V1EvBN1uO7t1RKlR5aPFSOLgOjsh6PB1rctfV0IB3jboMdCjErpVRxocVD3dG3wAbAOevxnU8KCgOWZT3WrQ+lygItHuquXgNigQe413nkn2f9fQbjriFKqdJMi4e6q3Bu3vrp3xhnoufsKMZh9vLA3wo9L6WUfWnxUPf0Pcb1ru7DOLpxZ+YD539HFy2lSjddw1WujATSMDrjPnnHVqswrs1bH+hbJHkppexDi4fKlTPAZ1mPpwJOObZKxTi0DsbREqVUaaXFQ+XaROAK0JC7XQpxbtbfx4HahZ+UUsoutHioXLuOcfl2MA6eu+fY6gzGgfNy6IFzpUovLR7KJguBU4AH8MEdW5m3Poaii5hSpZOu2commcCHWY9HcaczOlYCMRgHzh8pirSUUkVMi4ey2XpgN0bX3fE5ttAD50qVdlo8VJ68n/U3AGiVYws9cK5UaabFQ+XJAeB/GIfFJ+XYIhhj+0TPOFeqNNLiofLsnxjX0n0M43q62Zm3PvSMc6VKG12jVZ6d5+YFST4DHLK1MB849wb6FFleSqnCp8VD5ct4IBHoCAzKNjYFWJz1+NWiS0opVei0eKh8ucrNy5ZMIKd7fizI+vsExtkhSqnSQIuHyrcvgEigEfBCtrHHgUMYV8N6qUjzUkoVHi0eKt+uY1wsEYyD6NkXKvPWx8tFlJFSqrBp8VAFYg7GxdibktOxj+UYJw62BXyLMi2lVCHR4qEKRBLwZdbjf2YbGwtszHqsu66UKg20eKgCMwOj55UvOXXMNfe6egFd7JQq+XQtVgUmHpif9fjdbGN/wtixVRvoVXRJKaUKhRYPVaC+AjKA3kAbqzFpwLKsx3rgXKmSTouHKlAXMK55BTA621jzlXafAlyLKCOlVGHIV/FwcnKiS5cuPPHEE1SvXr2gclIl3OdZf58F6lmNOYRxwcRKwMCiTUopVaDyXDzeeOMNwsPD2bNnD6tWraJ169YAVK9enatXr/LKK68UWJKqZAkCdgAVMG4YZc289RFQdAkppQpcnorHkCFDmDZtGps3b+bVV1/FweHmJfGio6PZsWMHzz77bIElqUoe8yVLXgOqWI1ZAtzAuA6vd1GmpJQqQHkqHqNHj2bt2rW88MILrF+/Ptv4oKAgWrZsme/kVMm1BTgKVAaGW425BOzMevxi0SallCoweSoejRs3ZtOmTXccHxMTo8dAlGXr4y3A2WqMedeV9rpSqqTKU/GIi4vDw+POV0ht0aIFEREReU5KlQ7LMXpfeXJ7mViFcU56U6BLkeellMq/PBWPn376iddeew13d/ds41q0aMHQoUNZt26dzdP98MMPOXjwIAkJCURGRrJ69WqaNm1q1cbZ2ZkZM2Zw7do1EhMTWbFiBTVr1rRqU69ePTZs2EBycjKRkZF89tlnlCtXzqqNv78/QUFBpKSkcO7cOQICsh/AHTFiBCEhIZhMJvbv30/Hjh1tnqeyLAPjirtgnDR488hYMsaNokAPnCtVcomtUatWLbl48aJcunRJZs2aJRkZGbJo0SJZvHixXL9+Xf744w+pXr26zdPdtGmTBAQESIsWLaR169ayYcMGCQ0NlUqVKlnazJo1Sy5cuCAPP/ywtG/fXvbt2yd79uyxjHd0dJRjx47J1q1bpU2bNtK3b1+JioqSCRMmWNo0aNBAkpKSZOrUqeLj4yMjR46U9PR06dOnj6XNoEGDJCUlRYYMGSLNmzeXb775RmJiYqRGjRq5mhdXV1cREXF1dbX5cyhN4QISByIgva3G9RRjcIyAs93z1NDITeh6bRV5e2GNGjVk3rx5Eh0dLZmZmZKZmSlxcXGyYMGCXP+DvVd4eHiIiEi3bt0EEDc3N0lNTZWBAwda2jRr1kxERDp37iyA9O3bVzIyMqRmzZqWNsOGDZO4uDipUKGCADJp0iQ5fvy41XstXbpUNm3aZHm+f/9+mT59uuW5g4ODXL58WT744ANdyGyMrzCKxyqr4Y4CF8UYNbBI8tDQyG/oem0V+Z+Ih4eH1KxZUxwcHAo0uUaNGomISMuWLQWQhx9+WERE3N3drdqFhobKqFGjBJBx48bJkSNHrMY3aNBARETatm0rgPzyyy/y5ZdfWrUZMmSIxMXFCSAVKlSQ9PR06d+/v1WbRYsWyZo1a3LM1cnJSVxdXS1Ru3ZtXciywgejeGSA1LUa96kYo1baPUcNjdyEFo+bUSCXJ7l27RpRUVGISEFMDgAHBwemTZvGnj17OHnyJABeXl6kpqYSHx9v1TYyMhIvLy9Lm8jIyGzjzePu1sbd3Z2KFSvi4eFB+fLlc2xjnsbtPvroIxISEiwRFhaWxzkvfYIxThosh3Hex01Ls/4+BrgXbVJKqXzJfsvpXPj3v/99zzYiwn/+85+8TB6AmTNn0qpVK7p27ZrnaRSliRMn8sUXX1ieu7q6agG5xWygJzAU+ARIB4xb1J4EWgJPAovsk5xSymZ5Kh5jx4694zgRwcHBIV/FY/r06Tz++ON0797d6h9wREQEzs7OuLu7W219eHp6WroGR0RE0KlTJ6vpeXp6WsaZ/5qH3domPj6elJQUrl27RkZGRo5t7tQFOS0tjbS0tDzNb1mwBggHagEDuHnxRPgBmAA8hxYPpUqOPO22KleuXLYoX748jRo14ssvv+Tw4cPZus/m1vTp03nyySfp2bMnoaGhVuOCgoJIS0ujV6+b94No2rQp3t7eBAYGAhAYGIivry81atSwtOnduzfx8fGcOnXK0ubWaZjbmKeRnp5OUFCQVRsHBwd69eplaaNskwHMzXo8wmqM+TLtvYC8LTNKKfso8AMp33//vSxZssTm182cOVNiY2Ole/fu4unpaYmKFSta2syaNUtCQ0OlR48e0r59e9m7d6/s3bv35kGcrK66mzdvltatW0ufPn0kMjIyx666kydPlmbNmsnw4cNz7KprMpnk5ZdfFh8fH5kzZ47ExMRY9eK6W+iBtexRByQd4+B5C6tx+8UY/A+756ihcbfQ9doqCn6ir732msTGxtr8ujsJCAiwtHF2dpYZM2ZIdHS0JCUlycqVK8XT09NqOvXr15eNGzdKcnKyREVFyZQpU6RcuXJWbfz9/eW3336TlJQUOX/+vNV7mGPkyJESGhoqKSkpsn//funUqZMuZPmMlRjF42ur4W+JMXhvkeWhoZGX0PXaKgp+onPnzpXo6Gh7z5hdQxeynKMXRvGIxziB0BjuJZApxihvu+eooXGn0PX6ZuTpgPlLL72U4/AqVarQvXt3nnrqKebPn59jG1W27QDOYlzV6gXMx0EiMK602wvjFlKT7ZSdUsoWNlcc8xnlOYX5+IKzc9m+5IT+QrlzjMLY+vjdavirYgw+avf8NDTuFLpe3wyHrAc2qV+/frZhIkJsbCxJSUm2Tq5UcnV1JSEhATc3NxITE+2dTrFSBQjDuBntg0CgZWgk4IRx3scpu+Sm1N3oen1TnnZbXbx4saDzUGVIHEYH3b9hdNsNtAzdBPTHOOfj3ieiKqXsp0AuT6KUrWZl/X0GuHlnGPPlSp4r6nSUUjbKVfHIzMwkIyPDpkhPTy/s3FUJFgQcxLjD4N8sQ9dj3OujEdApx9cppYqHXO22Gj9+fIFe9FApMK531Ql4HZgK3OA6sBZ4HmPr46D9klNK3VWeDpire9MDa/d2H3AZqAb8FeOIh3GF3Q0YV8KqC9ywU3ZKZafr9U16zEPZjQlYmPX45vWutgIxGJdQ9C/6pJRSuZKn3lZmderUoV27dri7u+PomL0OLV68OD+TV2XAHGA0xpZHAyCUdGAFxp0/nsc4eVApVRzZfHKIs7OzLFu2TNLT0yUzM1MyMjIsJwlmZGRYIi/TLi2hJxPlPrZgnDT4qWVYD8Fyf3Mnu+enoWEOXa9vRp52W3366ac89dRTfPzxx/To0QMHBwcCAgLo06cPmzZt4ujRo7Rp0yYvk1ZlkLnb7t8xThGE3RinEVYFHrFPUkqpe7K54ly4cEG++eYbAaRatWqSmZkpDz/8sGX8zz//LLNmzbJ7ZbRn6C+U3Ec5kIsYWx/PW4Z/LsagH+yen4aGOXS9vhl52vKoWbMmBw8a3ShNJhMALi4ulvErV67kqaeeysukVRmUyc0bRQ23DDWfMNgfcEEpVbzkqXhERkZSvXp1wCgesbGxNGvWzDLezc2NihUrFkyGqkyYj3Ff865AawAOA+cxroD1hN3yUkrlLE/F48CBA3Tt2tXyfP369bz33ns8//zzvPjii7z99tvs37+/wJJUpV8EsCrr8c2tjx+y/urlSpQqjmze1/XQQw/JtGnTxMnJ6AlTt25dCQ4OtvS4Onv2rDRt2tTu++TsGbpv1PbwxzjukQjiCgI+YgxKE6hm9/w0NHS9toqCmZCDg4O0bt1aWrZsme2Wr2UxdCHLW5zEKCAjLMOOiDFoqN1z09DQ9fpm5Gm3lZubW7ZhIsKxY8c4efIkmZmZeZmsUpZuu9kPnA8u8lyUUneWp+IRFRXFmjVreO6556x6WSmVX4uB60ArwA+AH7PG9AA87ZKTUiq7PBWPL774gpYtW/L9998TFRXF//73P55++mntYaXyLYGb5WIoABeA/UA54Gn7JKWUylGe93k98MADMmXKFAkJCZHMzExJSEiQH374Qfr37y8VKlSw+z45e4buG817dME47pEM4g4Cb4kxaK/dc9Mo26HrtVUUzIS6dOkiX375pVy6dEkyMjIkJibG3jNm19CFLH9xjFsPnHsJZIgxqJHdc9Mou6Hr9c0osEuy79+/n5kzZzJv3jySkpJyPKiuVG6ZzzgfBhhngWzPGvKCPdJRSuUgX9WnQYMG8sEHH0hQUJBkZGRIWlqabNmyRf72t7/ZvTLaM/QXSv6iCsh1jK2PTiDwghhPz9k9N42yG7peW4XtL6pbt6688847cuDAAcnIyJD09HTZsWOHDBs2TDw8POw9Q8UidCHLfyzCKB7zQaCSQKIYg7rYPTeNshm6XluF7S8y37djz5498sYbb4iXl5e9Z6LYhS5k+Y+HMIpHEuYzzr8TY9BXds9No2yGrtdWYfuL3nnnHalbt669Ey/WoQtZwYT5jPNhIPCoGE/DBfQqBhpFH7pe34w8n+dx+fLlvLxUKZtYHzjfClwDvDBOGlRK2UuB9bZSqjAsBlKAdkAHMjHubw56pV2l7EuLhyrWYrhZLl4Dbl7raiDmm9YqpYqeFg9V7Jl3XT0PVGY3cBmoAvS1V0pKlXlaPFSx9ysQDFTGvLPKfPUr3XWllL0Uq+LRrVs31q1bR1hYGCJC//79rcYvXLgQEbGKTZs2WbWpWrUq33//PfHx8cTGxjJ//vxsV/719fVl9+7dmEwmLl68yHvvvZctl6effprTp09jMpk4duwYjz76aMHPsMo16wPn5l1XT6D3N1fKPvJUPOrVq8dDDz1kNax169Z8++23LFu2LNs//dxycXHh6NGjjBw58o5tNm3ahJeXlyWee8761+eSJUto2bIlvXv35vHHH6d79+7MnTvXMt7V1ZWtW7dy4cIFOnTowHvvvcfYsWMZOnSopY2fnx9Lly5lwYIFtGvXjjVr1rBmzRpatmyZp/lS+fcdkAp0ANoTBJzDuL953pY1pVT+2dy/d/Xq1bJt2zbL85o1a0p0dLQkJibKlStXJCMjQ5588sl89SEWEenfv7/VsIULF8rq1avv+BofHx8REenQoYNl2COPPCKZmZlSq1YtAeT111+X6Ohoq6v+Tpw4UU6fPm15vmzZMlm/fr3VtAMDA2X27NnaH9yO8T3GOR/fgMAYMZ7+ZPe8NMpO6Hp9M/K05dGpUye2bdtmef7yyy9z33330aZNG+rUqcPPP//Mu+++m5dJ31OPHj2IjIwkODiYWbNmUa1aNcs4Pz8/YmNjCQoKsgzbvn07N27coHPnzpY2u3fvJj093dJmy5Yt+Pj4UKVKFUub7du3c6stW7bg5+dXKPOkcsf6wPnirGd90JtEKVX08lQ8qlWrRlRUlOX5448/zi+//MKff/6JiLBq1Sp8fHwKLEmzzZs38/LLL9OrVy8++OAD/P392bRpE46Oxmx4eXlZ5QWQmZlJTEwMXl5eljaRkZFWbczP79XGPD4nTk5OuLq6WoUqWLu59cD5n8A+jJtE6YFzpYpanorH1atX8fb2BsDd3Z0uXbqwZcsWy/jy5ctTvnz5gsnwFj/++CPr16/nxIkTrF27lscff5xOnTrRo0ePAn8vW3300UckJCRYIiwszN4plUrzsv4aR6jMWx8v2yUXpcqyPBWP7du38+abb/L222/z3Xff4ejoyJo1ayzjW7RowaVLlwoqxzsKCQnh6tWrNG7cGICIiAhq1qxp1aZcuXJUq1aNiIgISxtPT+vdHObn92pjHp+TiRMn4ubmZok6derkb+ZUjr4D0oCOQFt+yHrWDtDODEoVpTwVjw8//JDTp08zdepU+vTpw7vvvktoaChg7L4ZNGgQP//8c0HmmaM6depQvXp1wsPDAQgMDKRq1aq0b9/e0qZnz544Ojpy4MABS5vu3btbbRn17t2b4OBg4uLiLG169epl9V69e/cmMDDwjrmkpaWRmJhoFargXQNWZT0eSgKwMevZS/ZJSKkyLM9H293c3LLdq7xixYrSunVrqVq1qs3Tc3FxkTZt2kibNm1ERGTUqFHSpk0bqVevnri4uMhnn30mnTt3Fm9vb+nZs6ccPnxYzpw5I05OTpZp/PTTTxIUFCQdO3aUBx98UM6cOSNLliyxyjk8PFy+/fZbadGihQwaNEiSkpJk6NChljZ+fn6SlpYm77zzjjRr1kzGjBkjqamp0rJlS+2VUQyiJ0avq3gQF/qJ8fSSgKPdc9Mo3aHrtVXYPQFL+Pv7S04WLlwoFStWlM2bN0tkZKSkpqZKSEiIfPPNN1KzZk2raVStWlWWLFkiCQkJEhcXJwsWLBAXFxerNr6+vrJ7924xmUxy6dIlef/997Pl8vTTT0twcLCkpKTI8ePH5dFHH9WFrJiEA8gZzJdqLycQLcbTnnbPTaN0h67XVmH7i3r27Cnvvvuu1bBXXnlFLly4IBEREfLFF1+Io2PZ/hWoC1nhxiiM4nEMBGaJ8XSh3fPSKN2h67VV2P6i3bt3y+LFiy3PW7VqJWlpaXL48GFZtmyZZGRk5PhrviyFLmSFG1VAkjEKSDdaivEwUYzb1do/P43SGbpe34w8HTBv3rw5hw8ftjx/6aWXSEhIoFu3bjz77LPMmzePl1/W7pOq8MQBS7Iej+Qk8AfGGSAD7JSRUmVLnoqHi4sLCQkJlud9+/Zl8+bNmEwmAA4dOmQ5D0SpwjIz6+9TgBezs55pryulikKeiselS5fo2LEjAI0aNaJVq1Zs3brVMr5atWqkpqYWTIZK3cFRYC9QARjKwqyhvTFuU6uUKkx5Kh5LlizhtddeY+3atWzZsoXY2FjWrl1rGd+hQwfOnj1bYEkqdSfmrY9hxFCeX9HLlShVNPJUPCZMmMCkSZOoV68eFy9eZMCAAcTHxwPG/TR69OjBunXrCjRRpXKyEogE6gD9+U/WUN11pVRRsPtR+9IY2iuj6OITjF5XOygvkCrG01Z2z0uj9IWu1zcj33cSdHFxwcfHBx8fn2x37FOqKHwDZAIPk0ELPXCuVJHIc/F44IEH2LFjB7GxsZw4cYITJ04QGxvLzz//TIcOHQoyR6Xu6jJgPuI2gq+yHr1AMbvLslKligPGJohNOnXqxK5du0hLS+OHH37g9OnTgHH+x3PPPYeTkxM9evTg0KFDBZ1vieHq6kpCQgJubm56kcQi0BP4GUgE6hBCIg2Av2QNVapg6HptzeZ9Xdu2bZNz586Jp6dntnE1a9aUc+fOydatW+2+T86eoftGiz5OYRz7GM6zYjxcZPecNEpX6Hp9M/K0Xd+5c2e++eabbHfbA4iKimLu3Ll06dIlL5NWKs/MRzteZx3G8j0QqGS/hJQqxfJUPG7cuHHXOwWWK1eOGzdu5DkppfJiMXAdaM11/FiBXq5EqcKTp+Kxb98+Ro4cSf369bONq1evHiNGjGDv3r35Tk4pW8QBy7IeD+eTrEev2ScZpUq5PB0wb9u2Lbt376Z8+fKsXr3acjZ5s2bN6N+/PxkZGXTr1o1jx44VdL4lhh5Ys48HgENAKlCfy0RRB2gFnLRrXqp00PXaWp4OljRv3lxWrVoliYmJkpmZKZmZmZKYmCgrV66U5s2b2/1gjr1DD6zZLwIxDpz/i8FiPJxu95w0Skfoen0z8rTlcSsHBwdq1KgBwNWrVxERKlWqhLu7u+Xe4mWR/kKxn+eAH4ArOOFNEhmYgNpAsn0TUyWertc35fssKhEhKiqKqKgoRIw6NGrUKC5dupTv5JTKixVAOFCbNAYyHXDDOGlQKVVQ9BRcVeqkA3OyHr/B1KxHI+yUjVKlkxYPVSp9A6QBDxFOe/YCbQA/+yalVCmixUOVSpHA/7Iej+LdrEe69aFUQdHioUqtL7P+Psd+6nMBeAbwsGNGSpUedz5N/Dbt2rXL9URr166dp2SUKkhBwDaMG9O+y3u8yXLgb8Bnds1LqdIg1111MzMzLb2p7jlRBwdE5K6XMCnttEtf8WC+2q6JcnhzhaskA40BvXyOsp2u1zfl+r/7K6+8Uph5KFUodmCccd6RTN7gM/6PqcAjwCb7JqZUCZfvkwRVzvQXSvHxJLAKiOU+6hNJEr8A/eyclSqJdL2+SQ+Yq1JvDRAMVMXEML4B/go0sGdKSpV4WjxUqSfcPET+DhNxIh292q5S+aPFQ5UJ32Pc67w2MbzEYuDvgJN9k1KqBNPiocqEdODzrMcfMAFHqmHcaVAplRdaPFSZMQ+IBpoQyjP8D3jDzhkpVXJp8VBlRjIwLevxv/gEBzoDne2XkFIlmBYPVaZMB+KBVpziSVYDb9s5I6VKJi0eqkyJB77Kevwv/gM8BdSzX0JKlVDFqnh069aNdevWERYWhojQv3//bG3GjRvHlStXuH79Otu2baNx48ZW46tWrcr3339PfHw8sbGxzJ8/HxcXF6s2vr6+7N69G5PJxMWLF3nvvfeyvc/TTz/N6dOnMZlMHDt2jEcffbRgZ1bZzTQgEWjH7zzOZvTYh1J5Y/d74Zqjb9++8sknn8iAAQNERKR///5W499//32JjY2VJ554Qnx9fWXNmjXyxx9/iLOzs6XNTz/9JEeOHJFOnTrJQw89JGfPnpUlS5ZY3YM4PDxcFi9eLC1atJDBgwdLcnKyDB061NLGz89P0tPT5d133xUfHx8ZP368pKamSsuWLfVex6UkJmLc5/wQHQRiBCrbPSeN4h+6XluF3RPIMXIqHleuXJHRo0dbnru5uYnJZJLBgwcLID4+PiIi0qFDB0ubRx55RDIzM6VWrVoCyOuvvy7R0dFSoUIFS5uJEyfK6dOnLc+XLVsm69evt3rvwMBAmT17ti5kpSQ8QBIwCsiTrBT4wO45aRT/0PX6ZhSr3VZ3c//991OrVi22b99uGZaQkMCBAwfw8zPuEOfn50dsbCxBQUGWNtu3b+fGjRt07tzZ0mb37t2kp6db2mzZsgUfHx+qVKliaXPr+5jbmN8nJ05OTri6ulqFKr6ucfN+H5/wbxx5G3C5yyuUUrcqMcXDy8sLgMjISKvhkZGRlnFeXl5ERUVZjc/MzCQmJsaqTU7TuPU97tTGPD4nH330EQkJCZYICwuzdRZVEfsciAFacorn2QoMt3NGSpUcJaZ4FHcTJ07Ezc3NEnXq1LF3SuoeEoDJWY/HMYYKvAVUsmNGSpUcJaZ4REREAODp6Wk13NPT0zIuIiKCmjVrWo0vV64c1apVs2qT0zRufY87tTGPz0laWhqJiYlWoYq/GUA40JAQXmU9uvWhVO6UmOIREhJCeHg4vXr1sgxzdXWlc+fOBAYGAhAYGEjVqlVp3769pU3Pnj1xdHTkwIEDljbdu3e3usth7969CQ4OJi4uztLm1vcxtzG/jyo9rgP/yXr8bz6hEm8AerxKqdyw+1F7c7i4uEibNm2kTZs2IiIyatQoadOmjdSrV0/A6KobExMj/fr1k1atWsnq1atz7KobFBQkHTt2lAcffFDOnDlj1VXXzc1NwsPD5dtvv5UWLVrIoEGDJCkpKVtX3bS0NHnnnXekWbNmMmbMGO2qW4qjAsifGD2vxvMvgTF2z0mjeIau11Zh9wQs4e/vLzlZuHChpc24ceMkPDxcTCaTbNu2TZo0aWI1japVq8qSJUskISFB4uLiZMGCBeLi4mLVxtfXV3bv3i0mk0kuXbok77//frZcnn76aQkODpaUlBQ5fvy4PProo7qQleJ4EqN4pOAkjTgi4GH3nDSKX+h6fTP0NrSFRG9XWfJsAfoAK3mKp+kKvGPnjFRxo+v1TSXmmIdShe1tIBMYyCoeog1Q384ZKVV8afFQKsspYEHW46n8E/g/O2ajVPGmxUOpW4wBknCkCwd4gQqAj71TUqpY0uKh1C0igE+5AcDnvEdVPrBvQkoVU1o8lLrNVOAUTngSxWT2Ag/YOyWlih0tHkrdJh0YRhoAQ5lPV563b0JKFUNaPJTKwR5gHpUBmMtcnOhj34SUKma0eCh1B++TRCSVaU4wH+IDONs7JaWKDS0eSt1BHPAWxn1fPmY2LQiwaz5KFSdaPJS6ix9JZR11cCKd+fyOI972TkmpYkGLh1L3MIIwEqiEHwcZRU97p6NUsaDFQ6l7CANG4wbApyyhHb3u/gKlygAtHkrlwnwiWI0PzqSxknNUwcPeKSllV1o8lMqlv3GeP6jL/VzkOxrgYO+ElLIjLR5K5VIcGQzkPkxUpB+H+ZC29k5JKbvR4qGUDY5yjpFZB80/4Rg9qW7njJSyDy0eStloIVuYTz/KcYOlZFDH3gkpZQdaPJSyWSZvEMxvtKEm8SynDhXsnZJSRUyLh1J5kMI5nqYZsVThQcJYSG1dmVSZosu7UnkUwnKe4yXSKc8LXGEB1bUHlioztHgolQ9bmM2zfEAG5RhCNN/gqgVElQlaPJTKlwxW8RUv8gmZODKURKbr1XdVGaDFQ6l8S+JHvmYIU7mBAyNJ5QvK2TsppQqVFg+lCkQE3zOXoUwD4G0ymWTfhJQqVFo8lCowwfyXFbzOdAA+AMbZNyGlCo0WD6UK1K98w07ezNoC+T/gX3bNR6nCocVDqQK3iumc4l2mAPAJMAld2VTposuzUoViLp8Tx0d8Chi7sDaDXglLlRpaPJQqNBOYxA0Gs4xkKtEbCMKBjvZOS6kCoMVDqUL1L5azns7s5hyN8UbYB4wHvR6WKtG0eChV6JZwktfpyEqW8izlgX8D+4EWds5MqbzS4qFUkThMPD14nud4huVEU432GLux3ke3QlTJo8VDqSITC/RnBXtoxUE28BgVESYDx4FH7JydUrYoUcVjzJgxiIhVnD592jLe2dmZGTNmcO3aNRITE1mxYgU1a9a0mka9evXYsGEDycnJREZG8tlnn1GunPWlJPz9/QkKCiIlJYVz584REBBQJPOnyoqviaAP/XibABYRSU2aYfTGWgs0snN2SuWWlJQYM2aMHD9+XDw9PS1RvXp1y/hZs2bJhQsX5OGHH5b27dvLvn37ZM+ePZbxjo6OcuzYMdm6dau0adNG+vbtK1FRUTJhwgRLmwYNGkhSUpJMnTpVfHx8ZOTIkZKeni59+vSxKVdXV1cREXF1dbX756ZRXMNBYKi4cVGmMFrSKC8CkgLyKYiL3fPTuD10vbYKuyeQ6xgzZowcOXIkx3Fubm6SmpoqAwcOtAxr1qyZiIh07txZAOnbt69kZGRIzZo1LW2GDRsmcXFxUqFCBQFk0qRJcvz4catpL126VDZt2mRTrrqQaeQ+6gisl2aclk08IgIiIGEgASDl7J6fhjl0vb4ZJWq3FUCTJk0ICwvjjz/+4Pvvv6devXoAdOjQAScnJ7Zv325pe+bMGS5cuICfnx8Afn5+HD9+nKioKEubLVu24O7uTsuWLS1tbp2GuY15GkoVvDCgH2f4hEdZTD/W8QcNqQ0sAk4CLwLl7ZmiUrcpUcXjwIEDDBkyhL59+zJ8+HDuv/9+fv31VypXroyXlxepqanEx8dbvSYyMhIvLy8AvLy8iIyMzDbePO5ubdzd3alYseIdc3NycsLV1dUqlLLND0BLNhBFS47zHp9xjeo0AxYDfwKjAV2yVHFQoorH5s2bWbFiBcePH2fr1q389a9/pUqVKgwaNMjeqfHRRx+RkJBgibCwMHunpEqkq8DfSaU7U2nH/YTwEZ8Sjhf1gKnAJWAm0MGueaqyrkQVj9vFx8dz9uxZGjduTEREBM7Ozri7u1u18fT0JCIiAoCIiAg8PT2zjTePu1ub+Ph4UlJS7pjLxIkTcXNzs0SdOnXyPX+qLAsCepNEDybRkAb8wd9YwCma4w6MAA4DR4G3AA97pqrKpBJdPFxcXGjUqBHh4eEEBQWRlpZGr169LOObNm2Kt7c3gYGBAAQGBuLr60uNGjUsbXr37k18fDynTp2ytLl1GuY25mncSVpaGomJiVahVP79BjxLGq1ZSCqtOEwvtrOE50nBidbANIyjJv8DHgW9h6EqMnY/ap/bmDJlinTv3l28vb3Fz89Ptm7dKlFRUeLh4SFgdNUNDQ2VHj16SPv27WXv3r2yd+/em70Dsrrqbt68WVq3bi19+vSRyMjIHLvqTp48WZo1aybDhw/XrroaxShqCnwiECNViJHXmSUHaWfpoSUgl0EmgLSye66lL3S9tgq7J5DrWLp0qYSFhUlKSopcunRJli5dKg0bNrSMd3Z2lhkzZkh0dLQkJSXJypUrxdPT02oa9evXl40bN0pycrJERUXJlClTpFy5clZt/P395bfffpOUlBQ5f/68BAQE6EKmUcyissAogfMCIr4clS8YJVepalVIzoN8DtINxNHuOZf80PXaKuyeQKkMXcg0iiYcBPoILBVIEidS5ClWyFr6yXWcrQpJFMh/QfqDuNk975IZul7fDIesB6qAubq6kpCQgJubmx7/UEWkEvAY8CzwVyqRSR+2MoA19GMN1UiwtMzEOJqyDziAcXj+HPrP4F50vb5Ji0ch0YVM2Zcr0B+jkPShHA50ZQ8DWMNjrKMJIdlekQj8jlFUzHEao9Aog67XN2nxKCS6kKnioyrwJMZWyV8AN+pyia7s4UH20YF9tOUElUjL9koTcAzrgnICcmhZNuh6fZMWj0KiC5kqnsoDDwJ9MTr2tgYcKUcGTTlLe37Lir204zjumLJNIR04D1zIitDbHodTev+p6Hp9kxaPQqILmSoZXIH2wANAx6xoCIADN2jIn1nF5DDt+ZX2nMCDpLtOMQ2jgETcIa4BMRh3N4kF7nzqbfGj6/VNWjwKiS5kquSqjnHxk463RO2scUI9LtGEc3hzgQaE4s0ZvDlPAy5Rl2jKc8Omd0vBON6ScJe/dxt369+MvM90ruh6fZNeqFMpdZtoYGtWmNXCXEgu0YpLeGNssVS1emU5MqhDGLUIx5NIvIjAiz/x4g+8CKMWUVQngaokU4UUyiNUBCoCNcg/E3AdoyClZD2/9e/dHs/B2DJSuaPFQymVC+HAuqy4lTvgnRUNyKQBF2nARbyBrhhbMXciuJJIFeJwJRE3ErL+XsONK7hyFTeu4ko0bsTiSgJuJOJGMq6YcCMNV9JxI5P7sqZ4X1bkxf/Q4mELLR5KqXyIx+iPdewO410xFxbwxCgm1bL+VicxK4znTYEKecqiPOm4cgk3LnIfEVTkKvcRTUXiqUgC95FIRZKoSDL3kUxFTFTkOveRQkVSqUgaV0lBOybnnhYPpVQhSsTo3Hsil+1dwVJMqt3y+G7hTgYViKUhsVkH+/OmPXAkH68vW7R4KKWKkcSsCLXhNeUxjr3cXlSqAJUxCtK9/rpmva/KLS0eSqkSLgPjJlpX7Z1ImVKi7+ehlFLKPrR4KKWUspkWD6WUUjbT4qGUUspmWjyUUkrZTIuHUkopm2nxUEopZTMtHkoppWymxUMppZTN9AzzQubq6mrvFJRSBUTX55u0eBQS80IWFhZm50yUUgXN1dW1zN8MSu8kWIhq166dqwXM1dWVsLAw6tSpUyoXSJ2/kk3nL3v7K1euFEFmxZtueRQiWxewxMTEUrlymun8lWw6fzfbKT1grpRSKg+0eCillLKZFo9iIDU1lbFjx5KammrvVAqFzl/JpvOncqIHzJVSStlMtzyUUkrZTIuHUkopm2nxUEopZTMtHkoppWymxaMYGDFiBCEhIZhMJvbv30/Hjh3tndI9ffjhhxw8eJCEhAQiIyNZvXo1TZs2tWqzc+dORMQqZs+ebdWmXr16bNiwgeTkZCIjI/nss88oV65cUc5KjsaMGZMt99OnT1vGOzs7M2PGDK5du0ZiYiIrVqygZs2aVtMorvMGEBISkm3+RIQZM2YAJe+769atG+vWrSMsLAwRoX///tnajBs3jitXrnD9+nW2bdtG48aNrcZXrVqV77//nvj4eGJjY5k/fz4uLi5WbXx9fdm9ezcmk4mLFy/y3nvvFep8FXeiYb8YNGiQpKSkyJAhQ6R58+byzTffSExMjNSoUcPuud0tNm3aJAEBAdKiRQtp3bq1bNiwQUJDQ6VSpUqWNjt37pRvvvlGPD09LeHq6moZ7+joKMeOHZOtW7dKmzZtpG/fvhIVFSUTJkyw+/yNGTNGjh8/bpV79erVLeNnzZolFy5ckIcffljat28v+/btkz179pSIeQPEw8PDat569eolIiL+/v4l8rvr27evfPLJJzJgwAAREenfv7/V+Pfff19iY2PliSeeEF9fX1mzZo388ccf4uzsbGnz008/yZEjR6RTp07y0EMPydmzZ2XJkiWW8a6urhIeHi6LFy+WFi1ayODBgyU5OVmGDh1q9+/TTmH3BMp07N+/X6ZPn2557uDgIJcvX5YPPvjA7rnZEh4eHiIi0q1bN8uwnTt3ypdffnnH1/Tt21cyMjKkZs2almHDhg2TuLg4qVChgl3nZ8yYMXLkyJEcx7m5uUlqaqoMHDjQMqxZs2YiItK5c+diP285xZdffinnzp0rFd9dTsXjypUrMnr0aKvv0GQyyeDBgwUQHx8fERHp0KGDpc0jjzwimZmZUqtWLQHk9ddfl+joaKv5mzhxopw+fdru3589Qndb2VGFChXo0KED27dvtwwTEbZv346fn58dM7Odu7s7ADExMVbDX3jhBa5evcrx48f59NNPue+++yzj/Pz8OH78OFFRUZZhW7Zswd3dnZYtWxZN4nfRpEkTwsLC+OOPP/j++++pV68eAB06dMDJycnqeztz5gwXLlywfG/Ffd5uVaFCBV588UX++9//Wg0vyd/dre6//35q1apl9X0lJCRw4MABq+8rNjaWoKAgS5vt27dz48YNOnfubGmze/du0tPTLW22bNmCj48PVapUKZqZKUb0woh25OHhQfny5YmMjLQaHhkZiY+Pj52ysp2DgwPTpk1jz549nDx50jL8hx9+4MKFC1y5coXWrVszefJkmjVrxsCBAwHw8vLKcd7N4+zpwIEDDBkyhDNnzlCrVi3GjBnDr7/+SqtWrfDy8iI1NZX4+Hir10RGRlryLs7zdrsBAwZQpUoVFi1aZBlWkr+725nzySnfW7+vWwshQGZmJjExMVZtQkJCsk3DPC4uLq4w0i+2tHiofJs5cyatWrWia9euVsPnzZtneXzixAnCw8PZsWMHDRs25M8//yzqNG2yefNmy+Pjx49z4MABLly4wKBBgzCZTHbMrOC9+uqrbNq0ifDwcMuwkvzdqaKhu63s6Nq1a2RkZODp6Wk13NPTk4iICDtlZZvp06fz+OOP8/DDD9/zxlcHDhwAsPRyiYiIyHHezeOKk/j4eM6ePUvjxo2JiIjA2dnZsqvO7NbvraTMW/369fnLX/7C/Pnz79quJH935nzutp5FRERk6y1Xrlw5qlWrVuK+06KixcOO0tPTCQoKolevXpZhDg4O9OrVi8DAQDtmljvTp0/nySefpGfPnoSGht6zfdu2bQEsv3ADAwPx9fWlRo0alja9e/cmPj6eU6dOFUbKeebi4kKjRo0IDw8nKCiItLQ0q++tadOmeHt7W763kjJvr7zyClFRUWzcuPGu7UrydxcSEkJ4eLjV9+Xq6krnzp2tvq+qVavSvn17S5uePXvi6OhoKZyBgYF0796d8uVv7rDp3bs3wcHBZW6XlZndj9qX5Rg0aJCYTCZ5+eWXxcfHR+bMmSMxMTFWvViKY8ycOVNiY2Ole/fuVt05K1asKIA0bNhQ/vWvf0n79u3F29tb+vXrJ+fPn5ddu3ZZpmHu7rl582Zp3bq19OnTRyIjI4tFd9YpU6ZI9+7dxdvbW/z8/GTr1q0SFRUlHh4eAkZX3dDQUOnRo4e0b99e9u7dK3v37i0R82YOBwcHCQ0NlYkTJ1oNL4nfnYuLi7Rp00batGkjIiKjRo2SNm3aSL169QSMrroxMTHSr18/adWqlaxevTrHrrpBQUHSsWNHefDBB+XMmTNWXXXd3NwkPDxcvv32W2nRooUMGjRIkpKStKuuhv1i5MiREhoaKikpKbJ//37p1KmT3XO6V9xJQECAAFK3bl3ZtWuXXLt2TUwmk5w9e1YmT55sda4AIPXr15eNGzdKcnKyREVFyZQpU6RcuXJ2n7+lS5dKWFiYpKSkyKVLl2Tp0qXSsGFDy3hnZ2eZMWOGREdHS1JSkqxcuVI8PT1LxLyZo3fv3iIi0qRJE6vhJfG78/f3z3F5XLhwoaXNuHHjJDw8XEwmk2zbti3bfFetWlWWLFkiCQkJEhcXJwsWLBAXFxerNr6+vrJ7924xmUxy6dIlef/99+3+Pdor9JLsSimlbKbHPJRSStlMi4dSSimbafFQSillMy0eSimlbKbFQymllM20eCillLKZFg+llFI20+KhVDEQEBCAiNChQwd7p6JUrmjxUGWG+R/0ncJ83wal1L3pJdlVmfPvf/87230ZAM6fP2+HbJQqmbR4qDJn06ZNVneMU0rZTndbKXULb29vRITRo0czatQoQkNDuX79Ort27crx9qoPP/wwu3fvJikpidjYWNasWZPjXSBr167N/PnzCQsLIyUlhT///JNZs2ZRoUIFq3bOzs58/vnnREVFkZSUxKpVq/Dw8Ci0+VUqr3TLQ5U57u7uVK9e3WqYiFjdf/3ll1/G1dWVmTNnUrFiRd566y127NiBr6+v5XalvXr1YtOmTfz555+MHTuW++67jzfeeIO9e/fSvn17Lly4AECtWrU4ePAgVapUYe7cuQQHB1OnTh2efvppKlWqZHU72+nTpxMbG8u4ceNo0KABo0aNYsaMGTz77LNF8MkoZRu7X9pXQ6MoIiAg4I6XkjeZTAKIt7e3iIgkJydL7dq1La/t2LGjiIh8/vnnlmG//fabRERESNWqVS3DfH19JSMjQxYtWmQZtmjRIsnIyJAOHTrcM7etW7daDf/8888lPT1d3Nzc7P75aWjcGrrlocqcESNGcPbsWathmZmZVs/XrFnDlStXLM8PHTrE/v37+etf/8ro0aPx8vKiXbt2TJ48mdjYWEu748ePs23bNv76178Cxp0hBwwYwPr163N1nGXu3LlWz3/99VfeeecdvL29OX78uM3zqlRh0eKhypyDBw/e8x/5uXPnsg07e/YsgwYNAoxjIwBnzpzJ1u706dP07duXSpUqUblyZdzd3Tlx4kSucrt48aLVc3Nhqlq1aq5er1RR0QPmShUjt28BmTk4OBRxJkrdnW55KJWDJk2aZBvWtGlTQkNDASwHw5s1a5atnY+PD1evXuX69euYTCbi4+Np1apVoearVFHTLQ+lcjBgwABq165ted6xY0e6dOnCpk2bAIiIiODIkSMEBATg7u5uadeyZUv69OnDTz/9BICIsGbNGvr166eXHlGlim55qDLn0UcfzfFcjH379nHjxg3AONt8z549zJ49G2dnZ0aNGsW1a9f47LPPLO3fe+89Nm3aRGBgIAsWLLB01Y2Pj2fs2LGWdv/85z/p06cPv/zyC3PnzuX06dPUqlWLZ555hq5du1p11VWqJLF7ly8NjaKIu3XVFREJCAiwdNUdPXq0vP3223LhwgUxmUzyyy+/iK+vb7Zp9uzZU3799VdJTk6WuLg4Wbt2rfj4+GRrV69ePVm0aJFERkaKyWSS8+fPy/Tp06VChQpWud3endff319ERPz9/e3++Wlo3BZ2T0BDo9jErcXD3rloaBTn0GMeSimlbKbFQymllM20eCillLKZA8b+K6WUUirXdMtDKaWUzbR4KKWUspkWD6WUUjbT4qGUUspmWjyUUkrZTIuHUkopm2nxUEopZTMtHkoppWymxUMppZTN/h/BMv3yzKJiMAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot train and test loss as a function of epoch:\n",
        "fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "fig.tight_layout(pad = 4.0)\n",
        "ax.plot( history.history['loss'], 'b', label = 'Train')\n",
        "ax.plot( history.history['val_loss'], 'r', label = 'Test')\n",
        "ax.set_xlabel('Epoch', fontsize = 12)\n",
        "ax.set_ylabel('Loss value', fontsize = 12)\n",
        "ax.legend()\n",
        "ax.set_title('Loss vs. Epoch for reg. strength 0.01', fontsize = 14);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRS_vh61Qz8b"
      },
      "source": [
        "### Compare the true and predicted values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ASvIE-SWM9To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b49868-6fdc-4b0a-9524-879ac4a4db5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 78.  , 116.45],\n",
              "       [152.  ,  85.94],\n",
              "       [200.  , 160.46],\n",
              "       [ 59.  ,  68.61],\n",
              "       [311.  , 188.09],\n",
              "       [178.  , 192.54],\n",
              "       [332.  , 205.29],\n",
              "       [132.  , 125.28],\n",
              "       [156.  , 148.67],\n",
              "       [135.  , 135.16],\n",
              "       [220.  , 201.41],\n",
              "       [233.  , 204.71],\n",
              "       [ 91.  ,  91.63],\n",
              "       [ 51.  ,  60.72],\n",
              "       [195.  , 231.07],\n",
              "       [109.  , 194.93],\n",
              "       [217.  , 194.69],\n",
              "       [ 94.  , 106.13],\n",
              "       [ 89.  , 140.99],\n",
              "       [111.  , 168.92],\n",
              "       [129.  , 210.73],\n",
              "       [181.  ,  89.35],\n",
              "       [168.  , 141.81],\n",
              "       [ 97.  ,  93.52],\n",
              "       [115.  ,  99.29],\n",
              "       [202.  , 196.36],\n",
              "       [ 84.  ,  69.57],\n",
              "       [147.  , 155.19],\n",
              "       [253.  , 167.05],\n",
              "       [144.  , 198.47],\n",
              "       [262.  , 178.66],\n",
              "       [115.  , 149.13],\n",
              "       [ 68.  , 175.96],\n",
              "       [ 65.  ,  68.13],\n",
              "       [252.  , 156.73],\n",
              "       [212.  , 200.64],\n",
              "       [142.  , 102.87],\n",
              "       [215.  , 238.84],\n",
              "       [180.  , 170.97],\n",
              "       [163.  , 202.8 ],\n",
              "       [151.  , 135.68],\n",
              "       [283.  , 168.84],\n",
              "       [ 66.  , 108.53],\n",
              "       [ 83.  , 126.49],\n",
              "       [214.  , 118.62],\n",
              "       [189.  , 240.51],\n",
              "       [302.  , 134.23],\n",
              "       [ 93.  , 144.95],\n",
              "       [178.  , 178.77],\n",
              "       [241.  , 219.58],\n",
              "       [ 52.  ,  68.59],\n",
              "       [144.  , 156.19],\n",
              "       [102.  , 120.42],\n",
              "       [200.  , 145.85],\n",
              "       [232.  , 188.62],\n",
              "       [ 97.  , 134.64],\n",
              "       [109.  , 157.87],\n",
              "       [ 55.  , 100.74],\n",
              "       [ 63.  ,  68.79],\n",
              "       [ 98.  ,  71.3 ],\n",
              "       [ 88.  ,  83.91],\n",
              "       [233.  , 180.58],\n",
              "       [235.  , 173.78],\n",
              "       [ 97.  , 101.05],\n",
              "       [243.  , 267.19],\n",
              "       [ 59.  ,  80.4 ],\n",
              "       [138.  ,  87.19],\n",
              "       [220.  , 175.12],\n",
              "       [137.  , 192.6 ],\n",
              "       [ 72.  ,  73.41],\n",
              "       [109.  , 191.07],\n",
              "       [ 71.  ,  86.04],\n",
              "       [ 74.  ,  76.01],\n",
              "       [219.  , 126.69],\n",
              "       [196.  , 155.77],\n",
              "       [170.  ,  78.76],\n",
              "       [199.  , 102.48],\n",
              "       [ 71.  ,  87.59],\n",
              "       [155.  , 248.36],\n",
              "       [ 52.  , 166.03],\n",
              "       [ 63.  , 101.38],\n",
              "       [ 88.  , 106.9 ],\n",
              "       [ 97.  , 149.67],\n",
              "       [100.  , 194.28],\n",
              "       [ 64.  , 107.84],\n",
              "       [107.  , 123.77],\n",
              "       [ 49.  , 118.52],\n",
              "       [ 60.  ,  67.42],\n",
              "       [346.  , 186.64]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "## Compare the true and predicted values\n",
        "np.column_stack((Y_test, model.predict(X_test_transformed)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}